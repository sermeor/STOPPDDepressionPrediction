{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4dc97ec-d621-4537-ae6a-1cd2eb9f7cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k2371000\\AppData\\Local\\Temp\\ipykernel_13600\\2851642576.py:629: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_demo[\"sex\"] = df_demo[\"sex\"].replace({\"F\":1, \"M\":2})\n",
      "C:\\Users\\k2371000\\AppData\\Local\\Temp\\ipykernel_13600\\2851642576.py:685: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sui = df_sui.groupby('src_subject_id').apply(summarize_group).reset_index()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Folder name with original input data.\n",
    "dir_input = 'Raw data/'\n",
    "\n",
    "#Folder name for output data.\n",
    "dir_output = 'Baseline/'\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#Data Extraction STOP-PD\n",
    "################################################################################\n",
    "# Sergio Mena Ortega, 2025\n",
    "\n",
    "#------------- Covariates ----------------------------------------\n",
    "#OUTPUT dataframe: df_covars\n",
    "\n",
    "df_covars = pd.read_excel(dir_input + 'pqdem01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_covars = df_covars[df_covars['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"site\"]\n",
    "\n",
    "df_covars = df_covars[selected_variables].copy()\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- Clinical Global impression (CGI) ------------------\n",
    "# OUTPUT dataframe: df_cgi\n",
    "df_cgi = pd.read_excel(dir_input + 'cgi01.xlsx', skiprows=[1]).filter(regex = \"^(src_subject_id$|cgi_si$|week$)\")\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_cgi = df_cgi[df_cgi['week'] == 0].drop(columns = 'week')\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Movement side eff. (AIMS) -------------------------------\n",
    "# OUTPUT dataframe: df_move\n",
    "df_move = pd.read_excel(dir_input + 'aims01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_move = df_move[df_move['week'] == 0].drop(columns = 'week')\n",
    "selected_variables = [\"src_subject_id\", \"aims_facial1_date1\", \"aims_facial2_date1\", \"aims_facial3_date1\", \"aims_facial4_date1\", \"aims_extrem5_date1\", \"aims_extrem6_date1\", \"aims_trunk_score_date1\", \"aims_global8_date1\", \"aims_global9_date1\", \"aims_global10_date1\", \"aims_dental11_date1\", \"aims_dental12_date1\", \"aimsmed_ttl\"]\n",
    "df_move = df_move[selected_variables].copy()\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Barnes Akathisia Rating Scale  --------------------\n",
    "# OUTPUT dataframe: df_aka\n",
    "df_aka = pd.read_excel(dir_input + 'bns01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_aka = df_aka[df_aka['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"bnsa3\", \"bnsa4\", \"bnsa1a\", \"bnsa2a\"]\n",
    "\n",
    "df_aka = df_aka[selected_variables].copy()\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Brief Psychiatric Rating Scale (BPRS)  ------------\n",
    "# OUTPUT dataframe: df_bprs\n",
    "df_bprs = pd.read_excel(dir_input + 'bprs01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_bprs = df_bprs[df_bprs['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"bprs_somc\", \"bprs_anxi\", \"bprs_depr\", \"bprs_guil\", \"bprs_host\", \"bprs_susp\", \n",
    "                    \"bprs_unus\", \"bprs_gran\", \"bprs_hall\", \"bprs_diso\", \"bprs_conc\", \"bprs_exci\", \n",
    "                    \"bprs_motr\", \"bprs_blun\", \"bprs_tens\", \"bprs_mann\", \"bprs_unco\", \"bprs_emot\", \n",
    "                    \"bprs_total\"]\n",
    "\n",
    "df_bprs = df_bprs[selected_variables].copy()\n",
    "\n",
    "#Remove 0 -> not assessed for individual terms\n",
    "for var in selected_variables[1:-1]:\n",
    "    df_bprs[var] = df_bprs[var].replace(0, np.nan)\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Delusion Assessment Scale (DAS)  ------------\n",
    "# OUTPUT dataframe: df_das\n",
    "df_das = pd.read_excel(dir_input + 'del01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_das = df_das[df_das['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables = [\n",
    "    \"src_subject_id\", \"das_1\", \"das_2\", \"das_3\", \"das_4\", \"das_5\", \"das_6\", \"das_7\", \"das_8\", \"das_9\", \n",
    "    \"das_10\", \"das_11\", \"das_12\", \"das_13\", \"das_14\", \"das_16\", \"das_impact\", \"das_disorg\", \n",
    "    \"das_convict\", \"das_bizzare\", \"das_extension\"\n",
    "]\n",
    "df_das = df_das[selected_variables].copy()\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Mattis Dementia Rating Scale (MDRS)  ------------\n",
    "# OUTPUT dataframe: df_mdrs\n",
    "df_mdrs = pd.read_excel(dir_input + 'mdrs01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_mdrs = df_mdrs[df_mdrs['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"drse\", \"drsf\", \"drsg\", \"drsh\", \"drsi\", \"drsj\", \"drsk\", \"drsl\", \"drsm\", \"drsn\", \"drso\", \"drs2\"]\n",
    "\n",
    "df_mdrs = df_mdrs[selected_variables].copy()\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- Hamilton Depression Rating Scale (HDRS)  ------------\n",
    "# OUTPUT dataframe: df_hrsd\n",
    "df_hrsd = pd.read_excel(dir_input + 'hrsd01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_hrsd = df_hrsd[df_hrsd['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"hsoin\", \"hmnin\", \"hemin\", \"hmdsd\", \"hpanx\", \"hinsg\", \"happt\", \"hwl\", \n",
    "    \"hsanx\", \"hhypc\", \"hvwsf\", \"hsuic\", \"hintr\", \"hengy\", \"hslow\", \"hagit\", \n",
    "    \"hsex\", \"hamd_02\", \"hamd_04\", \"hamd_22\", \"hamd_31\", \"hamd_32\", \n",
    "    \"hamd_33\", \"hamd_34\", \"hamd_35\", \"hamd_36\", \"hamd_score_24\"]\n",
    "\n",
    "\n",
    "df_hrsd = df_hrsd[selected_variables].copy()\n",
    "\n",
    "#Remove -9 -> not assessed for individual terms\n",
    "for var in selected_variables[1:]:\n",
    "    df_hrsd[var] = df_hrsd[var].replace(-9, np.nan)\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Mini-Mental State Examination (MMSE)  ------------\n",
    "# OUTPUT dataframe: df_mmse\n",
    "df_mmse = pd.read_excel(dir_input + 'mmse01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_mmse = df_mmse[df_mmse['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"mmse01\", \"mmse02\", \"mmse03\", \"mmse04\", \"mmse05\", \"mmse06\", \"mmse07\", \n",
    "                        \"mmse08\", \"mmse22\", \"mmse23\", \"mmse24\", \"mmse28\", \"mmse29\", \"mmse30\", \n",
    "                        \"mmse_ts\", \"mmse20_1\", \"mmse11_1\", \"mmse12_1\", \"mmse13_1\", \"mmse6_1\", \"mmse7_1\"]\n",
    "\n",
    "\n",
    "df_mmse = df_mmse[selected_variables].copy()\n",
    "\n",
    "#Remove 8 -> refused\n",
    "df_mmse['mmse12_1'] = df_mmse['mmse12_1'].replace(8, np.nan)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- Cardiovascular Risk Form (MMSE)  ------------\n",
    "# OUTPUT dataframe: df_cardio\n",
    "df_cardio = pd.read_excel(dir_input + 'screen01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_cardio = df_cardio[df_cardio['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"cr1\", \"cr2\", \"cr2a\", \"estrogen\", \"cr3\", \"cr3a\", \"cr3b\", \"cr3c\", \"cr4\",\n",
    "                      \"cr5a\", \"cr5b\", \"cr5c\", \"cr6\", \"cr7\", \"cr8a\", \"cr8b\", \"cr8c\", \"cr9\"]\n",
    "\n",
    "df_cardio = df_cardio[selected_variables].copy()\n",
    "\n",
    "#Dummy code variables. \n",
    "for var in [\"cr1\", \"cr2a\"]:\n",
    "    dummies = pd.get_dummies(df_cardio[var], prefix=var)\n",
    "    df_cardio = pd.concat([df_cardio, dummies], axis=1)\n",
    "    df_cardio.drop(var, axis=1, inplace=True)\n",
    "\n",
    "# Replace -7 values in the 'estrogen' column with NaN\n",
    "df_cardio['estrogen'] = df_cardio['estrogen'].replace(-7, np.nan)\n",
    "\n",
    "# Replace 9 values in the cr3 column with NaN or 0 depending on the value. \n",
    "df_cardio['cr3'] = df_cardio['cr3'].replace(9, np.nan)\n",
    "for var in [\"cr4\", \"cr9\"]:\n",
    "    df_cardio[var] = df_cardio[var].replace(9, 0)\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Cumulative Illness Rating Scale-Geriatric (CIRS)  ------------\n",
    "# OUTPUT dataframe: df_cirs\n",
    "df_cirs = pd.read_excel(dir_input + 'crs01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_cirs = df_cirs[df_cirs['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"heart\", \"vsclr\", \"hema\", \"eyes\", \"ugi\", \"lgi\", \"renal\", \n",
    "                  \"genur\", \"mskl\", \"neuro\", \"psych\", \"respiratory\", \"liverd\", \"endod\", \"cirscnt\", \"cirstot\"]\n",
    "\n",
    "df_cirs = df_cirs[selected_variables].copy()\n",
    "\n",
    "\n",
    "\n",
    "#Remove -9 -> not known\n",
    "for var in [\"eyes\", \"ugi\", \"lgi\", \"renal\", \"genur\", \"mskl\", \"neuro\", \"liverd\"]:\n",
    "    df_cirs[var] = df_cirs[var].replace(-9, np.nan)\n",
    "    \n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- Electrocardiogram (ECG)  --------------------------\n",
    "# OUTPUT dataframe: df_ecg\n",
    "df_ecg = pd.read_excel(dir_input + 'ecg01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_ecg = df_ecg[df_ecg['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"ecghr\", \"ecgpr\", \"ecgqrs\", \"ecgqt\", \"ecgqtc\", \"crfint\"]\n",
    "\n",
    "df_ecg = df_ecg[selected_variables].copy()\n",
    "df_ecg[\"crfint\"] = df_ecg[\"crfint\"].replace(-9, np.nan)\n",
    "df_ecg\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- MacArthur Competence Assessment Tool - Clinical Research (MACCAT)  --------------------------\n",
    "# OUTPUT dataframe: df_maccat\n",
    "df_maccat = pd.read_excel(dir_input + 'maccomp01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_maccat = df_maccat[df_maccat['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables = [\"src_subject_id\",\n",
    "    \"matu1a\", \"matu1b\", \"matu1c\", \"matu1d\", \"matu2\", \"matu3a\", \"matu3b\", \"matu3c\", \n",
    "    \"matu4a\", \"matu4b\", \"matu4c\", \"matu4d\", \"matu5\", \"matu6\", \"mata1\", \"mata2\", \n",
    "    \"mata3\", \"mata4\", \"matr1\", \"matr2\", \"matr3\", \"matr4\", \"matr5\", \"matc1\", \"maccattot\"\n",
    "]\n",
    "df_maccat = df_maccat[selected_variables].copy()\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Physical Examination (PE) -------------------------\n",
    "# OUTPUT dataframe: df_pe\n",
    "df_pe = pd.read_excel(dir_input + 'pe01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_pe = df_pe[df_pe['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"pex003a\", \"pex004a\", \"pex005a\", \"pex007a\", \"pex010a\", \"pex012a\", \"hdnkpe\", \"neurope\", \"pe_4\", \"phys9\"]\n",
    "df_pe = df_pe[selected_variables].copy()\n",
    "\n",
    "\n",
    "for var in [\"pex003a\", \"pex004a\", \"pex005a\", \"pex007a\", \"pex010a\", \"pex012a\", \"hdnkpe\", \"neurope\"]:\n",
    "    #Remove 7 and -9\n",
    "    df_pe[var] = df_pe[var].replace(-9, np.nan)\n",
    "    df_pe[var] = df_pe[var].replace(7, np.nan)\n",
    "    \n",
    "    #Change all into just abnormal. \n",
    "    df_pe[var] = df_pe[var].replace(3, 2)\n",
    "    df_pe[var] = df_pe[var].replace(4, 2)\n",
    "    df_pe[var] = df_pe[var].replace(5, 2)\n",
    "    df_pe[var] = df_pe[var].replace(6, 2)\n",
    "\n",
    "#Convert to not known. \n",
    "df_pe[\"pe_4\"] = df_pe[\"pe_4\"].replace(-99, np.nan)\n",
    "df_pe[\"pe_4\"] = df_pe[\"pe_4\"].replace(0, np.nan)\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "#------------- Schedule for Affective Disorders and Schizophrenia - Delusional Scale -------------------------\n",
    "# OUTPUT dataframe: df_ksads\n",
    "df_ksads = pd.read_excel(dir_input + 'ksads_diagnoses01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_ksads = df_ksads[df_ksads['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"sadsd1\", \"sadsd2\"]\n",
    "\n",
    "df_ksads = df_ksads[selected_variables].copy()\n",
    "\n",
    "#Remove no sufficient info 0 -> np.nan.\n",
    "df_ksads[\"sadsd2\"] = df_ksads[\"sadsd2\"].replace(0, np.nan)\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Simpson Angus Scale -------------------------------\n",
    "# OUTPUT dataframe: df_sas\n",
    "\n",
    "df_sas = pd.read_excel(dir_input + 'sas01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_sas = df_sas[df_sas['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"sas01\", \"sas02\", \"sas03\", \"sas04\", \"sas05\", \"sas06\", \"sas08\", \"sas09\", \"sas10\", \"sas_total\"]\n",
    "df_sas = df_sas[selected_variables].copy()\n",
    "\n",
    "#Remove 9 -> not ratable\n",
    "for var in selected_variables[1:-1]:\n",
    "    df_sas[var] = df_sas[var].replace(9, np.nan)\n",
    "    \n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- Scale for the Assessment of Positive Symptoms -------------------------------\n",
    "# OUTPUT dataframe: df_saps\n",
    "\n",
    "df_saps = pd.read_excel(dir_input + 'saps_sans01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_saps = df_saps[df_saps['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables = [\"src_subject_id\",  \"saps_h1\", \"saps_h2\", \"saps_h3\", \"saps_h4\", \"saps_h5\", \"saps_h6\",\n",
    "    \"saps_d1\", \"saps_d2\", \"saps_d3\", \"saps_d4\", \"saps_d5\", \"saps_d6\", \"saps_d7\", \"saps_d8\", \"saps_d9\", \"saps_d10\",\n",
    "    \"saps_d11\", \"saps_d12\", \"saps19\", \"saps20\", \"saps21\", \"saps22\", \"saps23\", \"saps_total\"] \n",
    "\n",
    "df_saps = df_saps[selected_variables].copy()\n",
    "\n",
    "#Change -1 to 1 -> present symptom for easiness of interpretation.\n",
    "for var in [\"saps_h1\", \"saps_h2\", \"saps_h3\", \"saps_h4\", \"saps_h5\", \"saps_h6\", \"saps_d1\", \"saps_d2\", \"saps_d3\", \n",
    "            \"saps_d4\", \"saps_d5\", \"saps_d6\", \"saps_d7\", \"saps_d8\", \"saps_d9\", \"saps_d10\",\"saps_d11\", \"saps_d12\"]:\n",
    "    df_saps[var] = df_saps[var].replace(-1, 1)\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Structured Clinical Interview for DSM-IV -------------------------------\n",
    "# OUTPUT dataframe: df_dsm\n",
    "\n",
    "df_dsm = pd.read_excel(dir_input + 'scid01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_dsm = df_dsm[df_dsm['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables = [\"src_subject_id\",\n",
    "    \"q001_bpi_life\", \"q006_bpi_mon\", \"q010_bpii_life\", \"q014_bpii_mon\", \"q018_obp_life\", \"q019_obp_current\",\n",
    "    \"q021_mdd_life\", \"q023_mdd_season\", \"q025_mdd_mon\", \"q026_mdd_current\", \"q027_mdd_sev\", \"q028_dysd_current\",\n",
    "    \"q031_depnos_life\", \"q032_depnos_mon\", \"q034_mdgmc_life\", \"q036_mdgmc_mon\", \"q038_simd_life\", \"q040_simd_mon\",\n",
    "    \"q042_sz_life\", \"q043_sz_mon\", \"q045_szp_life\", \"q046_szp_mon\", \"q048_sza_life\", \"q049_sza_mon\",\n",
    "    \"q051_dd_life\", \"q052_dd_mon\", \"q053_bfpd_life\", \"q054_bfpd_mon\", \"q055_pdgmc_life\", \"q057_pdgmc_mon\",\n",
    "    \"q060_sipd_life\", \"q062_sipd_mon\", \"q065_pdnos_life\", \"q066_pdnos_mon\", \"q067_al_life\", \"q068_al_mon\",\n",
    "    \"q069_sha_life\", \"q070_sha_mon\", \"q071_can_life\", \"q072_can_mon\", \"q073_stim_life\", \"q074_stim_mon\",\n",
    "    \"q075_op_life\", \"q076_op_mon\", \"q077_coc_life\", \"q078_coc_mon\", \"q079_hal_life\", \"q080_hal_mon\",\n",
    "    \"q081_poly_life\", \"q082_poly_mon\", \"q083_othsub_life\", \"q084_othsub_mon\", \"q085_panic_life\", \"q086_panic_agor\",\n",
    "    \"q087_panic_mon\", \"q088_agor_life\", \"q089_agor_mon\", \"q090_social_life\", \"q091_social_mon\", \"q092_phobia_life\",\n",
    "    \"q093_phobia_mon\", \"q094_ocd_life\", \"q095_ocd_mon\", \"q096_ptsd_life\", \"q097_ptsd_mon\", \"q098_gad_life\",\n",
    "    \"q099_adgmc_life\", \"q101_adgmc_month\", \"q103_siad_life\", \"q105_siad_mon\", \"q107_adnos_life\", \"q108_adnos_mon\",\n",
    "    \"q109_somat_life\", \"q110_pain_life\", \"q111_undiffsom_life\", \"q112_hypochon_life\", \"q113_bdd_life\", \n",
    "    \"q114_an_life\", \"q115_an_mon\", \"q116_bn_life\", \"q117_bn_mon\", \"q118_bed_life\", \"q119_bed_mon\", \"q120_adjd_life\",\n",
    "    \"q145_gaf\", \"cfmh_oth_suicideatt\", \"scids45\", \"scids35al\", \"scids35ap\", \"p2i4\", \"scids4d1\", \"scids4d3\", \n",
    "    \"scids4e\", \"dage\", \"scids4f\"\n",
    "]\n",
    "\n",
    "df_dsm = df_dsm[selected_variables].copy()\n",
    "\n",
    "#Correction of life, monthly and current scores \n",
    "temp_vars = [\"q001_bpi_life\", \"q006_bpi_mon\", \"q010_bpii_life\", \"q014_bpii_mon\", \"q018_obp_life\", \"q019_obp_current\",\n",
    "    \"q021_mdd_life\", \"q025_mdd_mon\", \"q027_mdd_sev\", \"q028_dysd_current\",\n",
    "    \"q031_depnos_life\", \"q032_depnos_mon\", \"q034_mdgmc_life\", \"q036_mdgmc_mon\", \"q038_simd_life\", \"q040_simd_mon\",\n",
    "    \"q042_sz_life\", \"q043_sz_mon\", \"q045_szp_life\", \"q046_szp_mon\", \"q048_sza_life\", \"q049_sza_mon\",\n",
    "    \"q051_dd_life\", \"q052_dd_mon\", \"q053_bfpd_life\", \"q054_bfpd_mon\", \"q055_pdgmc_life\", \"q057_pdgmc_mon\",\n",
    "    \"q060_sipd_life\", \"q062_sipd_mon\", \"q065_pdnos_life\", \"q066_pdnos_mon\", \"q067_al_life\", \"q068_al_mon\",\n",
    "    \"q069_sha_life\", \"q070_sha_mon\", \"q071_can_life\", \"q072_can_mon\", \"q073_stim_life\", \"q074_stim_mon\",\n",
    "    \"q075_op_life\", \"q076_op_mon\", \"q077_coc_life\", \"q078_coc_mon\", \"q079_hal_life\", \"q080_hal_mon\",\n",
    "    \"q081_poly_life\", \"q082_poly_mon\", \"q083_othsub_life\", \"q084_othsub_mon\", \"q085_panic_life\", \"q086_panic_agor\",\n",
    "    \"q087_panic_mon\", \"q088_agor_life\", \"q089_agor_mon\", \"q090_social_life\", \"q091_social_mon\", \"q092_phobia_life\",\n",
    "    \"q093_phobia_mon\", \"q094_ocd_life\", \"q095_ocd_mon\", \"q096_ptsd_life\", \"q097_ptsd_mon\", \"q098_gad_life\",\n",
    "    \"q099_adgmc_life\", \"q101_adgmc_month\", \"q103_siad_life\", \"q105_siad_mon\", \"q107_adnos_life\", \"q108_adnos_mon\",\n",
    "    \"q109_somat_life\", \"q110_pain_life\", \"q111_undiffsom_life\", \"q112_hypochon_life\", \"q113_bdd_life\", \n",
    "    \"q114_an_life\", \"q115_an_mon\", \"q116_bn_life\", \"q117_bn_mon\", \"q118_bed_life\", \"q119_bed_mon\", \"q120_adjd_life\",\n",
    "    \"cfmh_oth_suicideatt\", \"scids45\", \"scids35al\", \"scids35ap\", \"p2i4\", \"scids4d1\", \"scids4d3\", \n",
    "    \"scids4e\", \"dage\"\n",
    "]\n",
    "# 0 = Inadequate Information; 1 = Absent; 2 = Sub-Threshold; 3 = Threshold/Present; -8 = N/A; 999 = Missing -9 = Missing.\n",
    "for var in temp_vars:\n",
    "    df_dsm[var] = df_dsm[var].replace({0: np.nan, -8: np.nan, 999: np.nan, -9: np.nan, -7:np.nan})\n",
    "\n",
    "#Correct MDD categorical vars: q023_mdd_season #0 = Without Seasonal Pattern;1 = With Seasonal Pattern; 2=not recurrent\n",
    "#q026_mdd_current: 0 = Neither Melancholic, Atypical, nor Catatonic;1 = Melanchonic;2 = Atypical;3 = Catatonic;4=Anxious Distress; 5=Mixed Features\n",
    "for var in [\"q023_mdd_season\", \"q026_mdd_current\"]:\n",
    "    dummy_vars = pd.get_dummies(df_dsm[var], prefix=var)\n",
    "    df_dsm = pd.concat([df_dsm, dummy_vars], axis=1)\n",
    "    df_dsm.drop(columns=[var], inplace=True)\n",
    "\n",
    "#Correct number of MDD episodes 1=1; 2=2-3; 3=>3; 4=>1,unknown if >3. We make it 1=1, 2=more than 1\n",
    "df_dsm[\"scids4f\"] = df_dsm[\"scids4f\"].replace({3:2, 4:2})\n",
    "\n",
    "#Correct GAF: 0-100, 999 -> missing.\n",
    "df_dsm[\"q145_gaf\"] = df_dsm[\"q145_gaf\"].replace({900:np.nan})\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Short Form (36) Health Survey -------------------------------\n",
    "# OUTPUT dataframe: df_sf36\n",
    "\n",
    "df_sf36 = pd.read_excel(dir_input + 'sf36v201.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_sf36 = df_sf36[df_sf36['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables = [\"src_subject_id\",\n",
    "    \"sf3601\", \"sf3602\", \"sf3603a\", \"sf3603b\", \"sf3603c\", \"sf3603d\", \"sf3603e\", \"sf3603f\", \"sf3603g\", \"sf3603h\", \n",
    "    \"sf3603i\", \"sf3603j\", \"sf3604a\", \"sf3604b\", \"sf3604c\", \"sf3604d\", \"sf3605a\", \"sf3605b\", \"sf3605c\",\n",
    "    \"sf3609a\", \"sf3609b\", \"sf3609c\", \"sf3609d\", \"sf3609e\", \"sf3609f\", \"sf3609g\", \"sf3609h\", \"sf3609i\", \"sf3610\", \n",
    "    \"sf3611a\", \"sf3611b\", \"sf3611c\", \"sf3611d\", \"sf36_pf\", \"sf36_rp\", \"sf36_re\", \"sf36_p\", \"sf36_sf\", \"sf36_mh\", \n",
    "    \"sf36_ghp\", \"sf3607b\", \"sf3608b\", \"socialact\", \"mosvti\", \"mospcs\", \"mosmcs\"\n",
    "]\n",
    "\n",
    "df_sf36 = df_sf36[selected_variables].copy()\n",
    "\n",
    "#Correct  1 = Excellent; 2 = Very good; 3 = Good; 4 = Fair; 5 = Poor; -9 = Missing value; -97=Missing Online; -98=Purposely Skipped Online\n",
    "temp_vars = [\"sf3601\", \"sf3602\", \"sf3603a\", \"sf3603b\", \"sf3603c\", \"sf3603d\", \"sf3603e\", \"sf3603f\", \"sf3603g\", \"sf3603h\", \n",
    "    \"sf3603i\", \"sf3603j\", \"sf3604a\", \"sf3604b\", \"sf3604c\", \"sf3604d\", \"sf3605a\", \"sf3605b\", \"sf3605c\",\n",
    "    \"sf3609a\", \"sf3609b\", \"sf3609c\", \"sf3609d\", \"sf3609e\", \"sf3609f\", \"sf3609g\", \"sf3609h\", \"sf3609i\", \"sf3610\", \n",
    "    \"sf3611a\", \"sf3611b\", \"sf3611c\", \"sf3611d\", \"sf3607b\", \"sf3608b\"]\n",
    "for var in temp_vars:\n",
    "    df_sf36[var] = df_sf36[var].replace({-9:np.nan, -97: np.nan, -98:np.nan})\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Scale for Suicide Ideation – Worst ----------------\n",
    "# OUTPUT dataframe: df_ssi\n",
    "\n",
    "df_ssi = pd.read_excel(dir_input + 'ssi01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_ssi = df_ssi[df_ssi['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables  = [\"src_subject_id\",\n",
    "    \"ssi1\", \"ssi2\", \"ssi3\", \"ssi4\", \"ssi5\", \"ssi6\", \"ssi7\", \"ssi8\", \"ssi9\", \n",
    "    \"ssi10\", \"ssi11\", \"ssi12\", \"ssi13\", \"ssi14\", \"ssi15\", \"ssi16\", \"ssi17\", \n",
    "    \"ssi18\", \"ssi19\", \"ssitot\"\n",
    "]\n",
    "\n",
    "#Generate total score\n",
    "df_ssi[\"ssitot\"] = df_ssi[selected_variables[1:]].sum(axis=1)\n",
    "\n",
    "\n",
    "df_ssi = df_ssi[selected_variables].copy()\n",
    "\n",
    "#Correct -9 -> np.nan (incomplete)\n",
    "for var in selected_variables[1:]:\n",
    "    df_ssi[var] = df_ssi[var].replace(-9, np.nan)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Stroop Test ----------------\n",
    "# OUTPUT dataframe: df_stroop\n",
    "\n",
    "df_stroop = pd.read_excel(dir_input + 'stroop01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_stroop = df_stroop[df_stroop['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables  = [\"src_subject_id\", \"stroop1\", \"stroop2\", \"stroop3\"]\n",
    "\n",
    "df_stroop = df_stroop[selected_variables].copy()\n",
    "\n",
    "#Calculation of derived scores\n",
    "#SCORING THE STROOP TEST, ARTHUR R. JENSEN, University of California, Berkeley, Calif., USA\n",
    "#Color-naming factor (D)\n",
    "df_stroop['stroop_color_naming_score'] = df_stroop['stroop2']/(df_stroop['stroop2'] + df_stroop['stroop1'])\n",
    "\n",
    "# Interference Score (E)\n",
    "df_stroop['stroop_interference_score'] = df_stroop['stroop3'] - df_stroop['stroop2']\n",
    "\n",
    "# Cognitive Control Index\n",
    "df_stroop['stroop_cognitive_control_index'] = (df_stroop['stroop3'] - df_stroop['stroop1'])\n",
    "\n",
    "# Facilitation Score (H)\n",
    "df_stroop['stroop_facilitation_score'] = df_stroop['stroop2'] - df_stroop['stroop1']\n",
    "\n",
    "# Relative Interference Score (K)\n",
    "df_stroop['stroop_relative_interference_score'] = (df_stroop['stroop3']-df_stroop['stroop2'])/(df_stroop['stroop1'])\n",
    "\n",
    "# Reaction Time Variability\n",
    "stroop_tasks = ['stroop1', 'stroop2', 'stroop3']\n",
    "df_stroop['stroop_reaction_time_variability'] = df_stroop[stroop_tasks].std(axis=1) / df_stroop[stroop_tasks].mean(axis=1)\n",
    "\n",
    "# (F)\n",
    "#df_stroop['stroop_F'] = df_stroop['stroop2']/df_stroop['stroop1']\n",
    "# (G)\n",
    "#df_stroop['stroop_G'] = df_stroop['stroop2']/df_stroop['stroop3']\n",
    "# (I)\n",
    "#df_stroop['stroop_I'] = (df_stroop['stroop2'] - df_stroop['stroop1'])/(df_stroop['stroop2'] + df_stroop['stroop1'])\n",
    "# (J)\n",
    "#df_stroop['stroop_J'] = df_stroop['stroop1']/df_stroop['stroop2']\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- UKU Side Effect Rating Scale  ----------------\n",
    "# OUTPUT dataframe: df_uku\n",
    "\n",
    "df_uku = pd.read_excel(dir_input + 'uku01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_uku = df_uku[df_uku['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables = [\"src_subject_id\",\n",
    "    \"uku1\", \"uku2\", \"uku3\", \"uku4\", \"uku5\", \"uku6\", \"uku7\", \"uku8\", \"uku9\", \"uku10\", \n",
    "    \"uku11\", \"uku12\", \"uku13\", \"uku14\", \"uku15\", \"uku16\", \"uku17\", \"uku18\", \"uku19\", \"uku20\", \n",
    "    \"uku21\", \"uku22\", \"uku23\", \"uku24\", \"uku25\", \"uku26\", \"uku27\", \"uku28\", \"uku29\", \"uku30\", \n",
    "    \"uku31\", \"uku32\", \"uku33\", \"uku34\", \"uku35\", \"uku36\", \"uku37\", \"uku38\", \"uku39\", \"uku40\", \n",
    "    \"uku41\", \"uku42\", \"uku43\", \"uku44\", \"uku45\", \"uku46\", \"uku47\", \"uku48a\", \"uku48b\"\n",
    "]\n",
    "\n",
    "df_uku = df_uku[selected_variables].copy()\n",
    "\n",
    "#Correct 9 -> np.nan (NA)\n",
    "for var in selected_variables[1:]:\n",
    "    df_uku[var] = df_uku[var].replace(9, np.nan)\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Vitals  ----------------\n",
    "# OUTPUT dataframe: df_vitals\n",
    "\n",
    "df_vitals = pd.read_excel(dir_input + 'vitals01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_vitals = df_vitals[df_vitals['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "#Calculate BMI\n",
    "df_vitals[\"vt_bmi\"] = (df_vitals[\"blwt\"])/(df_vitals[\"vtl007\"]*df_vitals[\"vtl007\"]) * 703\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"vital_sysbp\", \"vital_diabp\", \"vital_pulse\", \"vtl004a\", \"vtl004b\", \"vtl004c\", \"blwt\", \"vtl007\", \"premorbidweight\", \"vt_bmi\"]\n",
    "\n",
    "\n",
    "\n",
    "df_vitals = df_vitals[selected_variables].copy()\n",
    "\n",
    "#Correct -> np.nan (NA)\n",
    "for var in selected_variables[1:]:\n",
    "    df_vitals[var] = df_vitals[var].replace({999:np.nan, -9:np.nan, -5:np.nan, -2:np.nan})\n",
    "\n",
    "    \n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- Blood tests  ----------------\n",
    "# OUTPUT dataframe: df_blood\n",
    "\n",
    "df_blood = pd.read_excel(dir_input + 'clinlabtests01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_blood = df_blood[df_blood['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"rsptc_no\", \"rsphdl_no\", \"rspldl_no\", \"rsptrig_no\", \"glorres\"]\n",
    "\n",
    "df_blood = df_blood[selected_variables].copy()\n",
    "\n",
    "#Calculate HDL/trig ratio. \n",
    "df_blood['hdl_trg_ratio'] = df_blood[\"rsphdl_no\"]/df_blood[\"rsptrig_no\"] \n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Antidepressant Treatment History Form  -----------\n",
    "# OUTPUT dataframe: df_athq\n",
    "\n",
    "df_athq = pd.read_excel(dir_input + 'athq01.xlsx', skiprows=[1])\n",
    "\n",
    "# Drop duplicates, there is no \"week column\" \n",
    "df_athq = df_athq.drop_duplicates(subset=['src_subject_id'])\n",
    "\n",
    "#\"b\" and \"c\"'s are confidence ratings of the evidence of history of medications, no need for prediction.\n",
    "selected_variables = [\"src_subject_id\", \"athf1a\", \"athf2a\", \"athf3a\", \n",
    "                      \"athf4a\",  \"athf5a\",  \"athf6a\", \"athf7a\",  \"athf8a\", \"athf9a\", \"athf10a\",  \"onsetepi\"]\n",
    "\n",
    "df_athq = df_athq[selected_variables].copy()\n",
    "df_athq\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Cornell Services Index  -----------\n",
    "# OUTPUT dataframe: df_suq\n",
    "\n",
    "df_suq = pd.read_excel(dir_input + 'suq01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_suq = df_suq[df_suq['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "selected_variables  = [\"src_subject_id\", \"sumhc38\", \"avghc39\", \"servicetype\", \"providertype\", \"servicesite\", \"servicereason\"]\n",
    "\n",
    "df_suq = df_suq[selected_variables].copy()\n",
    "\n",
    "# Compute sum of days and minutes spent for all medical visits. \n",
    "aggregated = df_suq.groupby(\"src_subject_id\").agg(\n",
    "    overall_mean_visits=(\"sumhc38\", \"sum\"),\n",
    "    overall_mean_time=(\"avghc39\", \"sum\")\n",
    ").reset_index()\n",
    "\n",
    "# Create dummy variables for service type, provider type, service site, and service reason\n",
    "dummies = pd.get_dummies(\n",
    "    df_suq[[\"src_subject_id\", \"servicetype\", \"providertype\", \"servicesite\", \"servicereason\"]],\n",
    "    columns=[\"servicetype\", \"providertype\", \"servicesite\", \"servicereason\"],\n",
    "    prefix=[\"servicetype\", \"providertype\", \"servicesite\", \"servicereason\"]\n",
    ")\n",
    "\n",
    "# Aggregate the dummy variables by patient since there are multiple entries per patient, so we get all the\n",
    "#cummulated services, sites and reasons in dummy coded variables.\n",
    "dummies_aggregated = dummies.groupby(\"src_subject_id\").max().reset_index()\n",
    "\n",
    "df_suq = pd.merge(aggregated, dummies_aggregated, on=\"src_subject_id\")\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Demographics  -----------\n",
    "# OUTPUT dataframe: df_demo\n",
    "\n",
    "df_demo = pd.read_excel(dir_input + 'pqdem01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_demo = df_demo[df_demo['week'] == 0].drop(columns = 'week')\n",
    "\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"sex\", \"ethnicity\", \"race\", \"demo_resp_status\", \"interview_age\", \"educat\", \"tx_code\", \n",
    "            \"eo4\", \"live\", \"entry_status\"]\n",
    "\n",
    "df_demo = df_demo[selected_variables].copy()\n",
    "\n",
    "#9 -> np.nan (missing, not applicable)\n",
    "for var in [\"demo_resp_status\", \"eo4\"]:\n",
    "    df_demo[var] = df_demo[var].replace(9, np.nan)\n",
    "\n",
    "\n",
    "# Dummy-code the specified categorical variables and add them to df_demo\n",
    "for var in [\"ethnicity\", \"race\", \"demo_resp_status\", \"live\", \"entry_status\"]:\n",
    "    dummies = pd.get_dummies(df_demo[var], prefix=var)\n",
    "    # Concatenate the dummy-coded variables with the original DataFrame\n",
    "    df_demo = pd.concat([df_demo.drop(columns=var), dummies], axis=1)\n",
    "\n",
    "#Convert sex to number\n",
    "df_demo[\"sex\"] = df_demo[\"sex\"].replace({\"F\":1, \"M\":2})\n",
    "\n",
    "#Treatment arms\n",
    "# Define binary treatment variables based on tx_code\n",
    "df_demo['treatment_olanzapine'] = 1  # All tx_code values include Olanzapine\n",
    "df_demo['treatment_sertraline'] = df_demo['tx_code'].apply(lambda x: 1 if x in [1, 3] else 0)\n",
    "df_demo['treatment_placebo'] = df_demo['tx_code'].apply(lambda x: 1 if x in [0, 2] else 0)\n",
    "df_demo['treatment_lithium'] = df_demo['tx_code'].apply(lambda x: 1 if x in [2, 3] else 0)\n",
    "\n",
    "#Drop tx_code\n",
    "df_demo.drop(columns=[\"tx_code\"], inplace = True)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Suicide attempts  -----------\n",
    "# OUTPUT dataframe: df_sui\n",
    "\n",
    "df_sui = pd.read_excel(dir_input + 'sibre01.xlsx', skiprows=[1])\n",
    "\n",
    "#DOES NOT INCLUDE VISIT NUMBER or WEEK, just age at age at initial interview and age at the time of the suicide attempt.\n",
    "#We will extract suicide attempts that happen before the initial interview since the rest might happen afterwards during the trial. \n",
    "#Change months to years.\n",
    "df_sui['interview_age'] = df_sui['interview_age']/12\n",
    "\n",
    "#Get entries where interview age is later than suicide attempt age.\n",
    "df_sui = df_sui[df_sui['interview_age']>=df_sui[\"suicatt_age\"]]\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"medthreat\", \"currentepi\"]\n",
    "\n",
    "df_sui = df_sui[selected_variables].copy()\n",
    "\n",
    "#Remove -9 -> Missing\n",
    "for var in [\"medthreat\", \"currentepi\"]:\n",
    "    df_sui[var] = df_sui[var].replace(-9, np.nan)\n",
    "\n",
    "#Some patients will have more than 1 suicide attempt. Calculate the number of suicide attempts and store \n",
    "# the variables \"medthreat\", \"currentepi\" of the highest threat one. Additionally, we register whether \n",
    "#any of the suicide attempts is from the current episode.\n",
    "\n",
    "# Group by subject ID and summarize each group\n",
    "def summarize_group(group):\n",
    "    # Count the number of suicide attempts\n",
    "    suicide_attempt_count = len(group)\n",
    "    \n",
    "    # Find the highest medthreat value (or NaN if all are NaN)\n",
    "    highest_medthreat = group['medthreat'].max() if group['medthreat'].notna().any() else np.nan\n",
    "    \n",
    "    # Check if any suicide attempt in the group is from the current episode\n",
    "    any_currentepi = 1 if group['currentepi'].eq(1).any() else 0\n",
    "    \n",
    "    return pd.Series({\n",
    "        'suicide_attempt_count': suicide_attempt_count,\n",
    "        'highest_medthreat': highest_medthreat,\n",
    "        'any_currentepi': any_currentepi\n",
    "    })\n",
    "\n",
    "# Apply the summarization function to each group\n",
    "df_sui = df_sui.groupby('src_subject_id').apply(summarize_group).reset_index()\n",
    "\n",
    "#Read IDS from all patients. \n",
    "df_temp = df_demo[['src_subject_id']].copy()\n",
    "\n",
    "# Merge with df_sui to include all patients, filling missing values for those without suicide attempts\n",
    "df_sui = df_temp.merge(df_sui, on='src_subject_id', how='left')\n",
    "\n",
    "# Fill NaN values for patients with no suicide attempts\n",
    "df_sui.loc[df_sui['suicide_attempt_count'].isna(), 'suicide_attempt_count'] = 0 # No attempts\n",
    "df_sui.loc[df_sui['suicide_attempt_count'] == 0, ['highest_medthreat', 'any_currentepi']] = 0 #medthreat 0 -> did not happen\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Protocol violators --------------------------------\n",
    "#OUTPUT dataframe: df_viol\n",
    "# Not for predictor battery. \n",
    "df_viol = pd.read_excel(dir_input + 'viol01.xlsx', skiprows=[1])\n",
    "selected_variables = [\"src_subject_id\", \"violate\", \"violationtype\", \"violationdays\"]\n",
    "\n",
    "df_viol = df_viol[selected_variables].copy()\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- Adverse effects to medication ---------------------\n",
    "#OUTPUT dataframe: df_adverse\n",
    "# Only able to use the adverse effects registered during or prior to baseline, which is a small minority of them.\n",
    "\n",
    "df_adverse = pd.read_excel(dir_input + 'adev01.xlsx', skiprows=[1])\n",
    "\n",
    "#Only adverse effects recorded prior or during baseline visit. Baseline is 1. \n",
    "df_adverse = df_adverse[df_adverse[\"start_dy\"]<=1]\n",
    "\n",
    "#Mark as 1 patients with adverse effects during or before baseline.\n",
    "df_adverse[\"AE_BEFORE\"] = 1\n",
    "\n",
    "#Read IDS from all patients. \n",
    "df_temp = df_demo[['src_subject_id']].copy()\n",
    "\n",
    "# Merge with df_sui to include all patients, filling missing values for those without suicide attempts\n",
    "df_adverse = df_temp.merge(df_adverse, on='src_subject_id', how='left')\n",
    "\n",
    "# Fill NaN values for patients with no suicide attempts\n",
    "df_adverse.loc[df_adverse['AE_BEFORE'].isna(), 'AE_BEFORE'] = 0 # No adverse effect.\n",
    "\n",
    "# Ongoing, severity, expected, serious. \n",
    "selected_variables = [\"src_subject_id\", \"AE_BEFORE\", \"aeongo\", \"aesev\", \"aeexp\", \"aeser\"]\n",
    "\n",
    "df_adverse = df_adverse[selected_variables].copy()\n",
    "\n",
    "#Replace -9, 99 -> np.nan unknown\n",
    "for var in selected_variables[1:]:\n",
    "    df_adverse[var] =  df_adverse[var].replace({-9:np.nan, 999:np.nan})\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Concomitant Medications ----------------------------\n",
    "#OUTPUT dataframe: df_concommed\n",
    "# Not for predictor battery. \n",
    "df_concommed = pd.read_excel(dir_input + 'med01.xlsx', skiprows=[1])\n",
    "selected_variables = [\"src_subject_id\", \"medication_name\", \"hi_31a5\", \"hi_31a6\"]\n",
    "\n",
    "df_concommed = df_concommed[selected_variables].copy()\n",
    "\n",
    "#Filter entries where start of finish of concommitant medication is before baseline. Baseline is 1. \n",
    "df_concommed = df_concommed[(df_concommed['hi_31a5'] <= 1) | (df_concommed['hi_31a6'] <= 1)]\n",
    "\n",
    "drug_atc_codes = {\n",
    "    \"LORAZEPAM\": \"N05BA06\",\n",
    "    \"ACETAMINOPHEN\": \"N02BE01\",\n",
    "    \"ATORVASTATIN\": \"C10AA05\",\n",
    "    \"ASPIRIN\": \"B01AC06\",\n",
    "    \"MULTIVITAMIN\": \"A11A\",\n",
    "    \"HYDROCHLOROTHIAZIDE\": \"C03AA03\",\n",
    "    \"LEVOTHYROXINE SODIUM\": \"H03AA01\",\n",
    "    \"WARFARIN SODIUM\": \"B01AA03\",\n",
    "    \"DOCUSATE SODUM\": \"A06AA02\",\n",
    "    \"DOCUSATE SODIUM\": \"A06AA02\",\n",
    "    \"LISINOPRIL\": \"C09AA03\",\n",
    "    \"LACTULOSE\": \"A06AD11\",\n",
    "    \"MILK OF MAGNESIA\": \"A06AD01\",\n",
    "    \"IBUPROFEN\": \"M01AE01\",\n",
    "    \"METFORMIN\": \"A10BA02\",\n",
    "    \"ATENOLOL\": \"C07AB03\",\n",
    "    \"CLONAZEPAM\": \"N03AE01\",\n",
    "    \"OMEPRAZOLE\": \"A02BC01\",\n",
    "    \"AL/MG HYDROXIDES/SIMETHICONE\": \"A02AB01\",\n",
    "    \"PANTOPRAZOLE SODIUM\": \"A02BC02\",\n",
    "    \"LOSARTAN\": \"C09CA01\",\n",
    "    \"FUROSEMIDE\": \"C03CA01\",\n",
    "    \"BENZTROPINE\": \"N04AC01\",\n",
    "    \"INSULIN\": \"A10AC01\",\n",
    "    \"SIMVASTATIN\": \"C10AA01\",\n",
    "    \"CYANOCOBALAMIN\": \"B03BA01\",\n",
    "    \"ACETAMINOPHEN/CODEINE\": \"N02AJ06\",\n",
    "    \"POTASSIUM CHLORIDE\": \"A12BA01\",\n",
    "    \"RAMIPRIL\": \"C09AA05\",\n",
    "    \"OLANZAPINE\": \"N05AH03\",\n",
    "    \"PREDNISONE\": \"H02AB06\",\n",
    "    \"ZOLPIDEM TARTRATE\": \"N05CF02\",\n",
    "    \"RISPERIDONE\": \"N05AX08\", \n",
    "    \"METOPROLOL\": \"C07AB02\",\n",
    "    \"METOPROLOL SUCCINATE\": \"C07AB02\",\n",
    "    \"VENLAFAXINE\": \"N06AX16\",\n",
    "    \"CALCIUM CARBONATE\": \"A12AA01\",\n",
    "    \"VALSARTAN\": \"C09CA03\",\n",
    "    \"ACETYL SALICYLIC ACID\": \"B01AC06\",\n",
    "    \"SENNA CONCENTRATE\": \"A06AX02\",\n",
    "    \"LATANOPROST\": \"S01EE01\",\n",
    "    \"VITAMIN E\": \"A11HA03\",\n",
    "    \"MULTI-VITAMIN\": \"A11HA\",\n",
    "    \"ENEMA SOD PHOS/SOD BIPHOS\": \"A06A\",\n",
    "    \"PSYLLIUM\": \"A06A\",\n",
    "    \"VITAMIN C\": \"A11GA01\",\n",
    "    \"CALCIUM/VIT D\": \"A11CC\",\n",
    "    \"NAPROXEN\": \"M01AE02\",\n",
    "    \"CITALOPRAM\": \"N06AB04\",\n",
    "    \"AMLODIPINE\": \"C08CA01\",\n",
    "    \"SERTRALINE\": \"N06AB06\",\n",
    "    \"TRAZODONE\": \"N06AX03\",\n",
    "    \"CLOPIDOGREL\": \"B01AC04\",\n",
    "    \"ALENDRONATE SODIUM\": \"M05BA03\",\n",
    "    \"DIGOXIN\": \"C01AA05\",\n",
    "    \"SALMETEROL XINAFOATE/FLUTICASONE PROPIONATE\": \"R03AK06\",\n",
    "    \"AMLODIPINE BESYLATE\": \"C08CA01\",\n",
    "    \"MIRTAZAPINE\": \"N06AX11\",\n",
    "    \"ESTROGEN\": \"G03CA01\",\n",
    "    \"ALBUTEROL INHALER\": \"R03BA02\",\n",
    "    \"ALPRAZOLAM\": \"N05BA12\",\n",
    "    \"FOLIC ACID\": \"B03BB01\",\n",
    "    \"SENNA\": \"A06AX02\",\n",
    "    \"NIFEDIPINE\": \"C08CA05\",\n",
    "    \"METAPROLOL TARTRATE\": \"C07AB02\",\n",
    "    \"PAROXETINE\": \"N06AB05\",\n",
    "    \"CELECOXIB\": \"M01AH01\",\n",
    "    \"Q-10 ENZYME\": \"A12CC\",\n",
    "    \"MAGNESIUM HYDROXIDE\": \"A02AA02\",\n",
    "    \"ENALAPRIL\": \"C09AA02\",\n",
    "    \"ALBUTEROL\": \"R03BA02\",\n",
    "    \"DILTIAZEM\": \"C08DB01\",\n",
    "    \"HYDROCODONE BITARTRATE/ACETAMINOPHEN\": \"N02AJ06\",\n",
    "    \"ENALAPRIL MALEATE\": \"C09AA02\",\n",
    "    \"GLIPIZIDE\": \"A10BB01\",\n",
    "    \"pioglitazone\": \"A10BG03\",\n",
    "    \"DONEPEZIL\": \"N06DA02\",\n",
    "    \"CORTISONE\": \"H02AB10\",\n",
    "    \"BLISTEX LIP OINTMENT\": \"D10AB\",\n",
    "    \"ROSIGLITAZONE\": \"A10BG02\",\n",
    "    \"HYDROCORTISONE\": \"H02AB09\",\n",
    "    \"PROPRANOLOL\": \"C07AA05\",\n",
    "    \"CARVEDILOL\": \"C07AG02\",\n",
    "    \"CIPROFLOXACIN HCL\": \"J01MA02\",\n",
    "    \"MORPHINE SULFATE\": \"N02AA01\",\n",
    "    \"ESOMEPRAZOLE MAGNESIUM\": \"A02BC05\",\n",
    "    \"BENZOCAINE\": \"C05AX04\",\n",
    "    \"RANITIDINE HCL\": \"A02BA02\",\n",
    "    \"BISACODYL\": \"A06AB07\",\n",
    "    \"OXYBUTYNIN\": \"G04BD06\",\n",
    "    \"PENICILLIN\": \"J01C\",\n",
    "    \"MAALOX\": \"A02AX07\",\n",
    "    \"VITAMINS\": \"A11\",\n",
    "    \"METRONIDAZOLE\": \"J01XD01\",\n",
    "    \"TAMSULOSIN\": \"G04CA02\",\n",
    "    \"ISOSORBIDE MONONITRATE\": \"C01DA08\",\n",
    "    \"MILK OF MAGNESIA/MINERAL OIL\": \"A06AD01\",\n",
    "    \"FLUTICASONE\": \"R03BA05\",\n",
    "    \"FAMOTIDINE\": \"A02BA03\",\n",
    "    \"BRIMONIDINE TARTRATE\": \"S01EC05\",\n",
    "    \"GLYBURIDE\": \"A10BB01\",\n",
    "    \"ALBUTEROL SULFATE\": \"R03BA02\",\n",
    "    \"CANDESARTAN\": \"C09CA06\",\n",
    "    \"CETIRIZINE\": \"R06AE07\",\n",
    "    \"MULTIVITAMIN W MINERALS\": \"A11AA\",\n",
    "    \"FINASTERIDE\": \"G04CB01\",\n",
    "    \"ENOXAPARIN SODIUM\": \"B01AB05\",\n",
    "    \"OXYBUTYNIN CHLORIDE\": \"G04BD04\",\n",
    "    \"QUETIAPINE\": \"N05AH04\",\n",
    "    \"RANITIDINE\": \"A02BA02\",\n",
    "    \"AMPICILLIN\": \"J01CA01\",\n",
    "    \"LEVOTHYROXINE\": \"H03AA01\",\n",
    "    \"FERROUS SULFATE\": \"B03AA07\",\n",
    "    \"CARBAMAZEPINE\": \"N03AF01\",\n",
    "    \"ISOSORBIDE DINITRATE\": \"C01DA08\",\n",
    "    \"SIMETHICONE\": \"A03AX13\",\n",
    "    \"TERAZOSIN\": \"C02CA04\",\n",
    "    \"DOXYCYCLINE\": \"J01AA02\",\n",
    "    \"OXYCODONE/ACETAMINOPHEN\": \"N02AJ06\",\n",
    "    \"ASPIRIN (ENTERIC COATED)\": \"B01AC06\",\n",
    "    \"SENNA CONCENTRATE 7 DOCUSATE SODIUM\": \"A06AB\",\n",
    "    \"GEMFIBROZIL\": \"C10AB04\",\n",
    "    \"Ezetimibe\": \"C10AX09\",\n",
    "    \"WARFARIN\": \"B01AA03\",\n",
    "    \"NAPROXEN SODIUM\": \"M01AE02\",\n",
    "    \"DORZOLAMIDE/TIMOLOL\": \"S01ED51\",\n",
    "    \"PETROLATUM\": \"D02AE\",\n",
    "    \"SENNA COMBINATION\": \"A06AB\",\n",
    "    \"CALCIUM\": \"A12AA\",\n",
    "    \"CHLORPHENIRAMINE/PSEUDOEPHDERINE\": \"R06AE07\",\n",
    "    \"ACETAMINOPHEN/PSEUDOEPHEDRINE HCL\": \"R05CF05\",\n",
    "    \"POLYETHYLENE GLYCOL\": \"A06AD15\",\n",
    "    \"REFECOXIB\": \"M01AH01\",\n",
    "    \"CLINDAMYCIN PHOSPHATE TOPICAL\": \"D10AF01\",\n",
    "    \"GUAIFENESIN\": \"R05CA03\",\n",
    "    \"NITROGLYCERIN PATCH\": \"C01DA02\",\n",
    "    \"CALCIPOTRIENE\": \"D05AX02\",\n",
    "    \"FLUDROCORTISONE\": \"A07EA01\",\n",
    "    \"CARBAMIDE PEROXIDE\": \"D08AC02\",\n",
    "    \"ANASTROZOLE\": \"L02BG03\",\n",
    "    \"RESOURCE\": \"A23AX\",\n",
    "    \"HYDROCHLOROTHIAZIDE AND LOSARTAN\": \"C09DA03\",\n",
    "    \"METFORMIN HCL\": \"A10BA02\",\n",
    "    \"VITAMIN A, C,/E\": \"A11HA\",\n",
    "    \"METOLAZONE\": \"C03BA04\",\n",
    "    \"CYCLOBENZAPRINE HCL\": \"M03BA07\",\n",
    "    \"TRIMETHOPRIM/SULFAMETHOXAZOLE\": \"J01EE01\",\n",
    "    \"LOPERAMIDE\": \"A07DA03\",\n",
    "    \"RALOXIFENE\": \"G03XC01\",\n",
    "    \"memantineHCl\": \"N06AX03\",\n",
    "    \"VITAMIN B1\": \"A11DA01\",\n",
    "    \"MEGESTROL ACETATE\": \"L02BA01\",\n",
    "    \"MESTINON\": \"N07AA01\",\n",
    "    \"CALCIUM CITRATE\": \"A12AA03\",\n",
    "    \"ESCITALOPRAM OXALATE\": \"N06AB10\",\n",
    "    \"Tramadol Hydrochloride\": \"N02AX02\",\n",
    "    \"VITAMIN B COMPLEX\": \"A11DA\",\n",
    "    \"SUMATRIPTAN SUCCINATE\": \"N02CC01\",\n",
    "    \"VERAPAMIL\": \"C08DA01\",\n",
    "    \"LOXAPINE\": \"N05AH02\",\n",
    "    \"IPRATROPIUM BROMIDE/ALBUTEROL SULFATE\": \"R03AK07\",\n",
    "    \"AZITHROMYCIN DIHYDRATE\": \"J01FA10\",\n",
    "    \"CALCIUM/VITAMIN D\": \"A12AA\",\n",
    "    \"ALENDRONATE\": \"M05BA04\",\n",
    "    \"VITAMIN B6\": \"A11DA03\",\n",
    "    \"METHYLCULLULOSE\": \"A06AD\",\n",
    "    \"IPRATROPIUM BROMIDE\": \"R03BB01\",\n",
    "    \"INDAPAMIDE\": \"C03BA11\",\n",
    "    \"PHENYTOIN\": \"N03AB02\",\n",
    "    \"CALCIUM WITH VITAMIN D\": \"A12AA\",\n",
    "    \"LANSOPRAZOLE\": \"A02BC03\",\n",
    "    \"QUINAPRIL\": \"C09AA08\",\n",
    "    \"L-TYROXINE\": \"H03AA01\",\n",
    "    \"INFLUENZA VACCINE\": \"J07BB02\",\n",
    "    \"TIMOLOL\": \"S01ED01\",\n",
    "    \"TAMOXIFEN CITRATE\": \"L02BA01\",\n",
    "    \"LEVOFLOXACIN\": \"J01MA12\",\n",
    "    \"NORTRIPTYLINE\": \"N06AA10\",\n",
    "    \"MONTELUKAST\": \"R03DC03\",\n",
    "    \"CYANOCOBALAMIN INJECTIONS IM\": \"B03BA01\",\n",
    "    \"BUDESONIDE\": \"R03BA02\",\n",
    "    \"MEDROXYPROGESTERONE\": \"G03AC05\",\n",
    "    \"ACETAZOLAMIDE\": \"C03BA01\",\n",
    "    \"DICLOFENAC SODIUM\": \"M01AB05\",\n",
    "    \"AMOXICILLIN/POTASSIUM CLAVULANATE\": \"J01CR02\",\n",
    "    \"PROPOXYPHENE NAPSYLATE/ACETAMINOPHEN\": \"N02AJ03\",\n",
    "    \"MELOXICAM\": \"M01AC06\",\n",
    "    \"AMOXICILLIN/POTASSIUM CLAVUNLANATE\": \"J01CR02\",\n",
    "    \"LOTEPREDNOL ETABONATE\": \"S01BA03\",\n",
    "    \"SULINDAC\": \"M01AC03\",\n",
    "    \"AMOXICILLIN TRIHYDRATE\": \"J01CA04\",\n",
    "    \"TELMISARTAN\": \"C09CA07\",\n",
    "    \"LOSARTAN/HCTZ\": \"C09DA01\",\n",
    "    \"TRIAMTERENE\": \"C03DB11\",\n",
    "    \"NITROFURANTOIN\": \"J01XE01\",\n",
    "    \"ISONIAZID\": \"J04AC01\",\n",
    "    \"TRIAMTERENE/HCTZ\": \"C03DB12\",\n",
    "    \"CEPACOL\": \"A01AD02\",\n",
    "    \"CHLOROSEPTIC THROAT SPRAY\": \"A01AD02\",\n",
    "    \"ASPIRIN BUFFERED\": \"B01AC06\",\n",
    "    \"ARTIFICIAL TEARS\": \"S01XA01\",\n",
    "    \"LISINOPRIL/HCTZ\": \"C09BA03\",\n",
    "    \"FLUVASTATIN\": \"C10AA08\",\n",
    "    \"OXYCODONE\": \"N02AA05\",\n",
    "    \"AMLODIPINE/BENAZEPRIL\": \"C09DB04\",\n",
    "    \"IRBESARTAN\": \"C09CA04\",\n",
    "    \"POLYMIXIN/BACITRACIN\": \"D06AX\",\n",
    "    \"ERYTHROMYCIN\": \"J01FA01\",\n",
    "    \"Insulin Glargine\": \"A10AE04\",\n",
    "    \"GLIMEPIRIDE\": \"A10BB12\",\n",
    "    \"HALOPERIDOL\": \"N05AD01\",\n",
    "    \"AMLODIPINE BENAZEPRIL HCL\": \"C09DB04\",\n",
    "    \"ACYCLOVIR\": \"J05AB01\",\n",
    "    \"Oxcarbazepine\": \"N03AF02\",\n",
    "    \"ENOXAPARIN\": \"B01AB05\",\n",
    "    \"Aripiprazole\": \"N05AX12\",\n",
    "    \"CALCIUM/MAGNESIUM\": \"A12AA01\",\n",
    "    \"ROLAIDS\": \"A02AX01\",\n",
    "    \"LIVAPLEX\": \"A11HA02\",\n",
    "    \"HYDROXYZINE HCL\": \"N05BB02\",\n",
    "    \"PROCHLORPERAZINE\": \"N05AA04\",\n",
    "    \"KETOCONAZOLE\": \"D01AC03\",\n",
    "    \"HYDROCORTISONE OINTMENT\": \"D07AA01\",\n",
    "    \"GLYCERIN SUPPOSITORY\": \"A06AD01\",\n",
    "    \"Oxymorphone Hydrochloride\": \"N02AA07\",\n",
    "    \"HYDROCODONE/ACETAMINOPHEN\": \"N02AA59\",\n",
    "    \"WATER/PETROLATUM\": \"D02AE\",\n",
    "    \"CYCLOSPORINE\": \"L04AD01\",\n",
    "    \"TEMAZEPAM\": \"N05CD07\",\n",
    "    \"AZATHIOPRINE\": \"L04AX01\",\n",
    "    \"TRIAMCINOLONE ACETONIDE\": \"D07AC08\",\n",
    "    \"PROTEIN DRINK\": \"A16AA01\",\n",
    "    \"FEXOFENADINE\": \"R06AX26\",\n",
    "    \"VALACYCLOVIR\": \"J05AB08\",\n",
    "    \"MELATONIN\": \"A11CM01\",\n",
    "    \"HYDROCHLOROTHIAZIDE/TRIAMTERENE\": \"C03DB11\",\n",
    "    \"SOTALOL HCL\": \"C07AA07\",\n",
    "    \"VALPROIC ACID\": \"N03AG01\",\n",
    "    \"PENTOXIFYLLINE\": \"C04AD01\",\n",
    "    \"BABY ASPIRIN\": \"B01AC06\",\n",
    "    \"INHALER\": \"R03AK\",\n",
    "    \"LACTOBACILLUS/PECTIN\": \"A07FA01\",\n",
    "    \"TOLTERODINE\": \"G04BD07\",\n",
    "    \"VALDECOXIB\": \"M01AH03\",\n",
    "    \"THEOPHYLLINE\": \"R03DA04\",\n",
    "    \"ESTRIOL/ESTRADIOL/ESTRONE\": \"G03CA01\",\n",
    "    \"VITAMIN D/CALCITRIOL\": \"A11CC01\",\n",
    "    \"MULTI-VITAMIN/IRON\": \"A11HA01\",\n",
    "    \"COLESEVELAM HYDROCHLORIDE\": \"C10AX08\",\n",
    "    \"BETHANECHOL CHLORIDE\": \"G04BA01\",\n",
    "    \"PROPRANOLOL/HCTZ\": \"C07AA05\",\n",
    "    \"ACETAMINOPHEN DIPHENHYDRAMINE\": \"R06AA04\",\n",
    "    \"BISACODYL/DIPHENYLMETHANE\": \"A06AB06\",\n",
    "    \"VITAMIN D\": \"A11CC\",\n",
    "    \"INDOMETHACIN\": \"M01AC01\",\n",
    "    \"MEGESTROL\": \"G03CB01\",\n",
    "    \"MULTIVITAMIN W CA/FE\": \"A11HA01\",\n",
    "    \"PENICILLIN VK\": \"J01CE01\",\n",
    "    \"VITAMIN C ROSE HIPS\": \"A11GA01\",\n",
    "    \"LACTASE\": \"A07FB01\",\n",
    "    \"CLOTRIMAZOLE\": \"D01AC01\",\n",
    "    \"REPAGLINIDE\": \"A10BX02\",\n",
    "    \"FLOVENT\": \"R03BA01\",\n",
    "    \"MIACALCIN CALCITONIN NASAL SPRAY\": \"H05AA01\",\n",
    "    \"SLEEP AID\": \"N05CC\",\n",
    "    \"BETAMETHASONE\": \"H02AB01\",\n",
    "    \"FLAXSEED OIL\": \"A11HA\",\n",
    "    \"THIAMINE HCL\": \"A11DA01\",\n",
    "    \"PILOCARPINE\": \"S01EA01\",\n",
    "    \"ISOMETHEPTENE MUCUS/DICHLORALPHENAZONE/AC\": \"R05CB02\",\n",
    "    \"STOOL SOFTENER\": \"A06AC01\",\n",
    "    \"CICLOPIROX\": \"D01AE13\",\n",
    "    \"LAMOTRIGINE\": \"N03AX09\",\n",
    "    \"ALBUTEROL NEBULIZE\": \"R03BA02\",\n",
    "    \"HYDROXYZINE PAMOATE\": \"N05BB02\",\n",
    "    \"METHADONE HCL\": \"N02AA02\",\n",
    "    \"ACETAMINOPHEN EXTRA STRENGTH\": \"N02BE01\",\n",
    "    \"LOVASTATIN\": \"C10AA02\",\n",
    "    \"GABAPENTIN\": \"N03AX12\",\n",
    "    \"VITAMIN C/CA/BIOFLAV\": \"A11GA01\",\n",
    "    \"POTASSIUM\": \"A12BA\",\n",
    "    \"COD LIVER OIL\": \"A11CA01\",\n",
    "    \"HUMULIN 70/30\": \"A10AD01\",\n",
    "    \"PIRBUTEROL\": \"R03AC08\",\n",
    "    \"ATENOLOL/CHLORTHALIDONE\": \"C07BB03\",\n",
    "    \"MEPERIDINE HCL\": \"N02AB02\",\n",
    "    \"SPIRONOLACTONE/HCTZ\": \"C03EB01\",\n",
    "    \"DORZOLAMIDE EYE DROPS\": \"S01EC03\",\n",
    "    \"BUPROPION\": \"N06AX12\",\n",
    "    \"IPRATROPIUM\": \"R03BB01\",\n",
    "    \"RISEDRONATE SODIUM\": \"M05BA07\",\n",
    "    \"DIMENHYDRINATE\": \"R06AA52\",\n",
    "    \"FENTANYL\": \"N02AB03\",\n",
    "    \"PRAVASTATIN\": \"C10AA03\",\n",
    "    \"VERAPAMIL HCL\": \"C08DA01\",\n",
    "    \"LITHIUM\": \"N05AN01\",\n",
    "    \"ACEBUTOLOL\": \"C07AB04\",\n",
    "    \"CHLORTHALIDONE\": \"C03BA04\",\n",
    "    \"SPIRONOLACTONE\": \"C03DA01\",\n",
    "    \"VITAMIN B COMPLEX PLUS C\": \"A11EA\",\n",
    "    \"FLUOXETINE\": \"N06AB03\",\n",
    "    \"D-METH/APAP/DOXYLAMINE/PE\": \"R06AA\",\n",
    "    \"NITROGLYCERIN\": \"C01DA02\",\n",
    "    \"ANALGESIC BALM OINTMENT\": \"M02AX10\",\n",
    "    \"BICALUTAMIDE\": \"L02BB03\",\n",
    "    \"DIAZEPAM\": \"N05BA01\",\n",
    "    \"CEFUROXIME\": \"J01DC02\",\n",
    "    \"TRAMADOL\": \"N02AX02\",\n",
    "    \"AMOXICILLIN\": \"J01CA04\",\n",
    "    \"AZELASTINE\": \"R06AX19\",\n",
    "    \"SALINE NASAL SPRAY\": \"R01AX\",\n",
    "    \"NIZATIDINE\": \"A02BA04\",\n",
    "    \"POLYCARBOPHIL\": \"A06AA12\",\n",
    "    \"AMOXAPINE\": \"N06AA17\",\n",
    "    \"OLMESARTAN MEDOXOMIL\": \"C09CA08\",\n",
    "    \"TRIAMCINOLONE ACETONIDE\": \"D07AC08\",\n",
    "    \"AMITRIPTYLINE\": \"N06AA09\",\n",
    "    \"AZITHROMYCIN\": \"J01FA10\",\n",
    "    \"METAXALONE\": \"M03BX06\",\n",
    "    \"CARISOPRODOL\": \"M03BA02\",\n",
    "    \"TRANDOLAPRIL\": \"C09AA10\",\n",
    "    \"COLESTIPOL\": \"C10AC02\",\n",
    "    \"FLUTICASONE PROPIONATE\": \"R01AD08\",\n",
    "    \"IRON\": \"B03AA\",\n",
    "    \"MAGNESIUM\": \"A12CC\",\n",
    "    \"METHIMAZOLE\": \"H03BB02\",\n",
    "    \"ELEMENTAL CALCIUM\": \"A12AA\",\n",
    "    \"CEPHALEXIN\": \"J01DB01\",\n",
    "    \"NITROGLYCERIN TRANSDERMAL\": \"C01DA52\",\n",
    "    \"SENNA/RHUBARB/ALF/FE\": \"A06AB06\",\n",
    "    \"NALTREXONE\": \"N07BB04\",\n",
    "    \"BENZONATATE\": \"R05DB01\",\n",
    "    \"DICYCLOMINE HCL\": \"A03AA07\",\n",
    "    \"IVF W_NSS\": \"B05BB01\",\n",
    "    \"NICOTINE PATCH\": \"N07BA01\",\n",
    "    \"TRAVOPROST\": \"S01EE04\",\n",
    "    \"PSEUDOEPHEDRINE HCL\": \"R01BA02\",\n",
    "    \"CEFTRIAXONE\": \"J01DD04\",\n",
    "    \"NICOTINE POLACRILEX\": \"N07BA01\",\n",
    "    \"METOCLOPRAMIDE\": \"A03FA01\",\n",
    "    \"GLUCOSAMINE CHONDROITIN\": \"M01AX05\",\n",
    "    \"SUCRALFATE\": \"A02BX02\",\n",
    "    \"ISOSORBIDE\": \"C01DA14\",\n",
    "    \"BETAXOLOL\": \"C07AB05\",\n",
    "    \"BENAZEPRIL\": \"C09AA07\",\n",
    "    \"ESTRADIOL\": \"G03CA03\",\n",
    "    \"PRAMIPEXOL\": \"N04BC05\",\n",
    "    \"ACETAMINOPHEN/ASPIRIN/CAFFEINE\": \"N02BA51\",\n",
    "    \"ZOLPIDEM\": \"N05CF02\",\n",
    "    \"LIDOCAINE\": \"N01BB02\",\n",
    "    \"PRAVASTATIN SODIUM\": \"C10AA03\",\n",
    "    \"NISOLDIPINE\": \"C08CA07\",\n",
    "    \"PROGESTERONE\": \"G03DA04\",\n",
    "    \"THYROID\": \"H03\",\n",
    "    \"DARBEPOETIN ALFA\": \"B03XA02\",\n",
    "    \"LEVAQUIN\": \"J01MA12\"\n",
    "}\n",
    "\n",
    "# Map medication names to ATC codes\n",
    "df_concommed['atc_code'] = df_concommed['medication_name'].map(drug_atc_codes)\n",
    "\n",
    "# Function to determine ATC group\n",
    "def categorize_drug(atcode):\n",
    "    if type(atcode)  == str: \n",
    "        if atcode[:3] == 'N01':\n",
    "            return 'CONCOMMED_ANESTHETICS'\n",
    "        elif atcode[:3] == 'N02':\n",
    "            return 'CONCOMMED_ANALGESICS'\n",
    "        elif atcode[:3] == 'N03':\n",
    "            return 'CONCOMMED_ANTIEPILEPTICS'\n",
    "        elif atcode[:3] == 'N04':\n",
    "            return 'CONCOMMED_ANTI-PARKINSON DRUGS'\n",
    "        elif atcode[:3] == 'N05':\n",
    "            return 'CONCOMMED_PSYCHOLEPTICS'\n",
    "        elif atcode[:3] == 'N06':\n",
    "            return 'CONCOMMED_PSYCHOANALEPTICS'\n",
    "        elif atcode[:3] == 'N07':\n",
    "            return 'CONCOMMED_OTHER_NSD'\n",
    "        else:\n",
    "            return 'CONCOMMED_OTHER_NON-NSD'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Add antidepressants and antipsychotics\n",
    "df_concommed['CONCOMMED_ANTIDEPRESSANTS'] = df_concommed['atc_code'].apply(lambda x: 1 if isinstance(x, str) and x.startswith('N06A') else 0)\n",
    "df_concommed['CONCOMMED_ANTIPSYCHOTICS'] = df_concommed['atc_code'].apply(lambda x: 1 if isinstance(x, str) and x.startswith('N05A') else 0)\n",
    "\n",
    "\n",
    "atc_categories = [\n",
    "    'CONCOMMED_ANESTHETICS',\n",
    "    'CONCOMMED_ANALGESICS',\n",
    "    'CONCOMMED_ANTIEPILEPTICS',\n",
    "    'CONCOMMED_ANTI-PARKINSON DRUGS',\n",
    "    'CONCOMMED_PSYCHOLEPTICS',\n",
    "    'CONCOMMED_PSYCHOANALEPTICS',\n",
    "    'CONCOMMED_OTHER_NSD'\n",
    "]\n",
    "\n",
    "concommed_all = atc_categories + ['CONCOMMED_ANTIDEPRESSANTS', 'CONCOMMED_ANTIPSYCHOTICS']\n",
    "\n",
    "# Add ATC group column\n",
    "df_concommed['atc_group'] = df_concommed['atc_code'].apply(categorize_drug)\n",
    "\n",
    "# Generate binary columns for each category\n",
    "for category in atc_categories:\n",
    "   df_concommed[category] = df_concommed['atc_group'].apply(lambda x: 1 if x == category else 0)\n",
    "\n",
    "# Aggregate binary columns at the subject level\n",
    "df_concommed = df_concommed.groupby('src_subject_id')[concommed_all].max().reset_index()\n",
    "\n",
    "#Read IDS from all patients. \n",
    "df_temp = df_demo[['src_subject_id']].copy()\n",
    "\n",
    "# Merge patients with no medication.\n",
    "df_concommed = df_temp.merge(df_concommed, on='src_subject_id', how='left')\n",
    "\n",
    "#Set all med columns as 0: no prior medication. \n",
    "df_concommed[concommed_all] = df_concommed[concommed_all].fillna(0).astype(int)\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Medication dosages ---------------------------------\n",
    "#OUTPUT dataframe: df_dosage\n",
    "\n",
    "df_dosage = pd.read_excel(dir_input + 'meds01.xlsx', skiprows=[1])\n",
    "\n",
    "# ONLY able to use initial medication dosage.\n",
    "selected_variables = [\"src_subject_id\", \"medication_name\", \"ddose\", \"stdate1\", \"spdate1\"]\n",
    "\n",
    "df_dosage = df_dosage[selected_variables].copy()\n",
    "\n",
    "#Only considering olanzapine, sertraline and placebo\n",
    "\n",
    "df_dosage = df_dosage[df_dosage[\"medication_name\"].isin([\"Olan\", \"Sert\", \"SertPbo\"])]\n",
    "\n",
    "# For each patient and medication, keep the entry with the closest stdate1: baseline dose. There are some delays on the time, this likely being due to prescription delays. \n",
    "df_dosage = df_dosage.loc[df_dosage.groupby([\"src_subject_id\", \"medication_name\"])[\"stdate1\"].idxmin().values]\n",
    "\n",
    "\n",
    "# Pivot the dataframe to get medication doses in separate columns\n",
    "df_dosage = df_dosage.pivot_table(index=\"src_subject_id\", \n",
    "                                 columns=\"medication_name\", \n",
    "                                 values=\"ddose\", \n",
    "                                 aggfunc=\"first\")\n",
    "\n",
    "# Rename the columns to match the desired output\n",
    "df_dosage = df_dosage.rename(columns={\"Olan\": \"olanzapine_dose\", \n",
    "                                    \"Sert\": \"sertraline_dose\", \n",
    "                                    \"SertPbo\": \"placebo_dose\"})\n",
    "df_dosage.reset_index(inplace=True)\n",
    "df_dosage.rename_axis(None, axis=1, inplace=True)\n",
    "\n",
    "# Fill NaN values with 0 if exactly two medications are present, if only one, we don't know the other one, so set as nan. \n",
    "for index, row in df_dosage.iterrows():\n",
    "    # Count how many non-NaN values are there\n",
    "    nan_count = row.isna().sum()\n",
    "\n",
    "    # If two doses are available, set the third one to 0\n",
    "    if nan_count < 2:\n",
    "        if pd.isna(row[\"olanzapine_dose\"]):\n",
    "            df_dosage.at[index, \"olanzapine_dose\"] = 0\n",
    "        elif pd.isna(row[\"sertraline_dose\"]):\n",
    "            df_dosage.at[index, \"sertraline_dose\"] = 0\n",
    "        elif pd.isna(row[\"placebo_dose\"]):\n",
    "            df_dosage.at[index, \"placebo_dose\"] = 0\n",
    "\n",
    "#-----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b234c104-6032-4fe2-97e2-5160ee9a14fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#Storing Data and Merging\n",
    "################################################################################\n",
    "# Sergio Mena Ortega, 2025\n",
    "\n",
    "#Writing individual datasets into excel.\n",
    "## IMPORTANT: violators not removed, bear in mind they will have to be removed if using these.\n",
    "df_covars.to_excel(dir_output+'Individual Datasets/covariates.xlsx', index = None)\n",
    "df_viol.to_excel(dir_output+'Individual Datasets/violators.xlsx', index = None)\n",
    "df_cgi.to_excel(dir_output+'Individual Datasets/cgi.xlsx', index = None)\n",
    "df_move.to_excel(dir_output+'Individual Datasets/move.xlsx', index = None)\n",
    "df_aka.to_excel(dir_output+'Individual Datasets/aka.xlsx', index = None)\n",
    "df_bprs.to_excel(dir_output+'Individual Datasets/bprs.xlsx', index = None)\n",
    "df_das.to_excel(dir_output+'Individual Datasets/das.xlsx', index = None)\n",
    "df_mdrs.to_excel(dir_output+'Individual Datasets/mdrs.xlsx', index = None)\n",
    "df_hrsd.to_excel(dir_output+'Individual Datasets/hrsd.xlsx', index = None)\n",
    "df_mmse.to_excel(dir_output+'Individual Datasets/mmse.xlsx', index = None)\n",
    "df_cardio.to_excel(dir_output+'Individual Datasets/cardio.xlsx', index = None)\n",
    "df_cirs.to_excel(dir_output+'Individual Datasets/cirs.xlsx', index = None)\n",
    "df_ecg.to_excel(dir_output+'Individual Datasets/ecg.xlsx', index = None)\n",
    "df_maccat.to_excel(dir_output+'Individual Datasets/maccat.xlsx', index = None)\n",
    "df_pe.to_excel(dir_output+'Individual Datasets/pe.xlsx', index = None)\n",
    "df_ksads.to_excel(dir_output+'Individual Datasets/ksads.xlsx', index = None)\n",
    "df_sas.to_excel(dir_output+'Individual Datasets/sas.xlsx', index = None)\n",
    "df_saps.to_excel(dir_output+'Individual Datasets/saps.xlsx', index = None)\n",
    "df_dsm.to_excel(dir_output+'Individual Datasets/dsm.xlsx', index = None)\n",
    "df_sf36.to_excel(dir_output+'Individual Datasets/sf36.xlsx', index = None)\n",
    "df_ssi.to_excel(dir_output+'Individual Datasets/ssi.xlsx', index = None)\n",
    "df_stroop.to_excel(dir_output+'Individual Datasets/stroop.xlsx', index = None)\n",
    "df_uku.to_excel(dir_output+'Individual Datasets/uku.xlsx', index = None)\n",
    "df_vitals.to_excel(dir_output+'Individual Datasets/vitals.xlsx', index = None)\n",
    "df_blood.to_excel(dir_output+'Individual Datasets/blood.xlsx', index = None)\n",
    "df_athq.to_excel(dir_output+'Individual Datasets/athq.xlsx', index = None)\n",
    "df_suq.to_excel(dir_output+'Individual Datasets/suq.xlsx', index = None)\n",
    "df_demo.to_excel(dir_output+'Individual Datasets/demo.xlsx', index = None)\n",
    "df_sui.to_excel(dir_output+'Individual Datasets/sui.xlsx', index = None)\n",
    "df_adverse.to_excel(dir_output+'Individual Datasets/adverse.xlsx', index = None)\n",
    "df_concommed.to_excel(dir_output+'Individual Datasets/concommed.xlsx', index = None)\n",
    "df_dosage.to_excel(dir_output+'Individual Datasets/dosage.xlsx', index = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fbdb872-ec3c-49fd-8c04-0d5ba9b19c84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### VARIABLE PRUNING to AVOID CURSE OF DIMENSIONALITY ###############\n",
    "#df_move = df_move[[\"src_subject_id\" ,\"aimsmed_ttl\"]].copy()\n",
    "#df_aka = df_aka[[\"src_subject_id\" ,\"bnsa4\"]].copy()\n",
    "#df_dsm = df_dsm[[\"src_subject_id\"]].copy()\n",
    "#df_bprs = df_bprs.copy()\n",
    "#df_das = df_das[[\"src_subject_id\", \"das_impact\", \"das_disorg\", \"das_convict\", \"das_bizzare\", \"das_extension\"]].copy()\n",
    "#df_mdrs = df_mdrs[[\"src_subject_id\", \"drs2\"]].copy()\n",
    "#df_hrsd = df_hrsd.copy()\n",
    "#df_mmse = df_mmse[[\"src_subject_id\", \"mmse_ts\"]].copy()\n",
    "#df_ksads = df_ksads.copy()\n",
    "#df_sas = df_sas[[\"src_subject_id\", \"sas_total\"]].copy()\n",
    "#df_saps = df_saps.copy()\n",
    "#df_ssi = df_ssi[[\"src_subject_id\", \"ssitot\"]].copy()\n",
    "#df_uku = df_uku.copy()\n",
    "#df_athq = df_athq.copy()\n",
    "#df_suq = df_suq[[\"src_subject_id\", \"overall_mean_visits\", \"overall_mean_time\"]].copy()\n",
    "#df_demo = df_demo[[\"src_subject_id\", \"sex\",\t\"interview_age\", \"educat\", \"eo4\", \"treatment_sertraline\", \"treatment_placebo\"]].copy()\n",
    "#df_sui = df_sui.copy()\n",
    "#df_adverse = df_adverse[[\"src_subject_id\", \"AE_BEFORE\"]].copy()\n",
    "#df_concommed = df_concommed[[\"src_subject_id\", \"CONCOMMED_ANTIDEPRESSANTS\", \"CONCOMMED_ANTIPSYCHOTICS\"]].copy()\n",
    "#df_dosage = df_dosage.copy()\n",
    "\n",
    "#df_vitals = df_vitals[[\"src_subject_id\", \"vt_bmi\"]].copy()\n",
    "#df_blood = df_blood.copy()\n",
    "#df_ecg = df_ecg[[\"src_subject_id\"]].copy()\n",
    "\n",
    "#df_sf36 = df_sf36.copy()\n",
    "#df_cardio = df_cardio.copy()\n",
    "#df_cirs = df_cirs.copy()\n",
    "#df_pe = df_pe.copy()\n",
    "\n",
    "#Merging data into 4 category: clinical_and_socio, biological, neurocog, quality of life/general health data used for model development. \n",
    "clin_dataframes = [df_cgi, df_move, df_aka, df_dsm, df_bprs, df_das, df_mdrs, df_hrsd, df_mmse, df_ksads, df_sas, df_saps, df_ssi, df_uku, \n",
    "                      df_athq, df_suq, df_demo, df_sui, df_adverse, df_concommed, df_dosage]\n",
    "bio_dataframes = [df_vitals, df_blood, df_ecg]\n",
    "qol_dataframes = [df_sf36, df_cardio, df_cirs, df_pe]\n",
    "neurocog_dataframes = [df_stroop]\n",
    "\n",
    "\n",
    "######################################################################\n",
    "\n",
    "df_clin = df_demo[[\"src_subject_id\"]].copy()\n",
    "for data in clin_dataframes:\n",
    "    df_clin = pd.merge(df_clin, data, on='src_subject_id', how='left')\n",
    "df_clin.to_excel(dir_output+'Merged Datasets/clin.xlsx', index = False)\n",
    "\n",
    "df_bio = df_demo[[\"src_subject_id\"]].copy()\n",
    "for data in bio_dataframes:\n",
    "    df_bio = pd.merge(df_bio, data, on='src_subject_id', how='left')\n",
    "df_bio.to_excel(dir_output+'Merged Datasets/bio.xlsx', index = False)\n",
    "\n",
    "df_qol = df_demo[[\"src_subject_id\"]].copy()\n",
    "for data in qol_dataframes:\n",
    "    df_qol = pd.merge(df_qol, data, on='src_subject_id', how='left')\n",
    "df_qol.to_excel(dir_output+'Merged Datasets/qol.xlsx', index = False)\n",
    "\n",
    "df_neurocog = df_demo[[\"src_subject_id\"]].copy()\n",
    "for data in neurocog_dataframes:\n",
    "    df_neurocog = pd.merge(df_neurocog, data, on='src_subject_id', how='left')\n",
    "df_neurocog.to_excel(dir_output+'Merged Datasets/neurocog.xlsx', index = False)\n",
    "\n",
    "\n",
    "# Merge all dataframes on 'src_subject_id'\n",
    "df_all = df_demo[[\"src_subject_id\"]].copy()\n",
    "df_all = df_all.merge(df_clin, on=\"src_subject_id\", how=\"left\")\n",
    "df_all = df_all.merge(df_bio, on=\"src_subject_id\", how=\"left\")\n",
    "df_all = df_all.merge(df_qol, on=\"src_subject_id\", how=\"left\")\n",
    "df_all = df_all.merge(df_neurocog, on=\"src_subject_id\", how=\"left\")\n",
    "\n",
    "# Save to Excel\n",
    "df_all.to_excel(dir_output + 'Merged Datasets/all_data.xlsx', index=False)\n",
    "\n",
    "#Save to excel.    \n",
    "df_covars.to_excel(dir_output+'Merged Datasets/covariates.xlsx', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
