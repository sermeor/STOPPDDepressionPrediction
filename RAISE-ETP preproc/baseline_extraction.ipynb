{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7edaeb2d-ee22-4126-b801-022409e8a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', 5)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Folder name with original input data.\n",
    "dir_input = 'Raw data/'\n",
    "\n",
    "#Folder name for output data.\n",
    "dir_output = 'Baseline/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5db871a8-42e8-47f7-8adf-8299c429996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#Data Extraction\n",
    "################################################################################\n",
    "# Sergio Mena Ortega, 2024\n",
    "\n",
    "\n",
    "#------------- PANSS ---------------------------------------------\n",
    "# OUTPUT dataframe: df_panss\n",
    "df_panss = pd.read_excel(dir_input + 'panss01.xlsx', skiprows=[1]).filter(regex = \"^(src_subject_id$|panss_total|pos_|neg_|gps_|visit$)\")\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_panss = df_panss[df_panss['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "# Sum positive scores, negative scores, and general scores (gps) separately\n",
    "df_panss['panss_ptotal'] = df_panss.filter(like='pos_').sum(axis=1)\n",
    "df_panss['panss_ntotal'] = df_panss.filter(like='neg_').sum(axis=1)\n",
    "df_panss['panss_gtotal'] = df_panss.filter(like='gps_').sum(axis=1)\n",
    "df_panss\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Clinical Global impression (CGI) ------------------\n",
    "# OUTPUT dataframe: df_cgi\n",
    "df_cgi = pd.read_excel(dir_input + 'cgis01.xlsx', skiprows=[1]).filter(regex = \"^(src_subject_id$|cs16$|visit$)\")\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_cgi = df_cgi[df_cgi['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Calgary Depression Scale for Schizophrenia --------\n",
    "# OUTPUT dataframe: df_cdss\n",
    "df_cdss = pd.read_excel(dir_input + 'clgry01.xlsx', skiprows=[1]).filter(regex = \"^(src_subject_id$|calg|visit$)\")\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_cdss = df_cdss[df_cdss['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "##Remove irrelevant cols. \n",
    "df_cdss.drop(columns = ['calg_s1', 'calg10', 'calg_s2'], inplace = True)\n",
    "\n",
    "\n",
    "##IMPORTANT: calgary is from 0 to 3, here it seems to start from 1, so we remove 1 to each col.\n",
    "calg_columns = ['calg1', 'calg2', 'calg3', 'calg4', 'calg5', 'calg6', 'calg7', 'calg8', 'calg9']\n",
    "df_cdss[calg_columns] = df_cdss[calg_columns].sub(1)\n",
    "\n",
    "# Recalculate the total in the calg_ts column\n",
    "df_cdss['calg_ts'] = df_cdss[calg_columns].sum(axis=1)\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Quality of Life  ----------------------------------\n",
    "# OUTPUT dataframe: df_qol\n",
    "df_qol = pd.read_excel(dir_input + 'qol01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter selected columns\n",
    "cols_to_use = ['src_subject_id', 'visit', \"qol02\", \"qol03\", \"qol04\", \"qol05\", \"qol06\", \"qol07\", \"qol08\", \"qol09\", \"qol10\", \"qol11\",\n",
    "    \"qol12\", \"qol13\", \"qol14\", \"qol15\", \"qol16\", \"qol17\", \"qol18\", \"qol19\", \"qol20\", \"qol21\", \"qol22\", \"intr_rel\", \"inst_rol\", \"intr_fou\", \n",
    "    \"com_obj\", \"qol_tot\", \"d1reltsx\", \"d2roltsx\",\"d3foutsx\", \"d4comtsx\", \"qlstsx\", \"a1reltsx\", \"a2roltsx\", \"a3foutsx\", \"a1relts\", \"a2rolts\",\n",
    "    \"a3fouts\"]\n",
    "\n",
    "\n",
    "df_qol = df_qol[cols_to_use].copy()\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_qol = df_qol[df_qol['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "## set 9 -> NaN in selected columns.\n",
    "for col in [\"qol02\", \"qol03\", \"qol04\", \"qol05\", \"qol06\", \"qol07\", \"qol08\", \"qol09\", \"qol10\", \"qol11\", \"qol12\", \"qol13\", \"qol14\", \"qol15\", \"qol16\", \"qol17\", \"qol18\", \"qol19\", \"qol20\", \"qol21\", \"qol22\"]:\n",
    "    df_qol.loc[df_qol[\"qol02\"] == 9, col] = np.nan\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Study compliance  ---------------------------------\n",
    "# OUTPUT dataframe: df_compliance\n",
    "\n",
    "df_compliance = pd.read_excel(dir_input + 'Intent_to_Attend.xlsx')\n",
    "\n",
    "df_compliance = df_compliance[['src_Subject_ID','Visit', 'How likely is it that you will complete the study?', 'How likely is it that you will attend the next in-person assessment?']].copy()\n",
    "\n",
    "# Define the new column names\n",
    "new_column_names = {\n",
    "    'src_Subject_ID': 'src_subject_id',\n",
    "    'Visit': 'visit',\n",
    "    'How likely is it that you will complete the study?': 'completion_likeliness', \n",
    "    'How likely is it that you will attend the next in-person assessment?': 'next_assessment_likeliness'\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "df_compliance = df_compliance.rename(columns=new_column_names)\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_compliance = df_compliance[df_compliance['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "#Dummy code categorical cols. \n",
    "dummy_coded_df_compliance = pd.get_dummies(df_compliance, columns=['completion_likeliness', 'next_assessment_likeliness'])\n",
    "df_compliance.drop(columns = ['completion_likeliness', 'next_assessment_likeliness'], inplace = True)\n",
    "df_compliance = df_compliance.merge(dummy_coded_df_compliance, on = 'src_subject_id', how= 'left')\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- SF-12 Survey (health) -------------------------------\n",
    "# OUTPUT dataframe: df_sf12\n",
    "\n",
    "df_sf12 = pd.read_excel(dir_input + 'sf1201.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_sf12 = df_sf12[df_sf12['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "sf12_list = ['src_subject_id', 'sf01', 'sf02', 'sf03', 'sf04', 'sf05', 'sf06', 'sf07', 'sf08', 'sf09', 'surm029', 'surm030', 'surm031',\n",
    "    'physical', 'mental', 'rawpcs12', 'rawmcs12']\n",
    "\n",
    "#Get selected columns.\n",
    "df_sf12 = df_sf12[sf12_list].copy()\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- Vitals --------------------------------------------\n",
    "# OUTPUT dataframe: df_vitals\n",
    "\n",
    "df_vitals = pd.read_excel(dir_input + 'vitals01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_vitals = df_vitals[df_vitals['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "selected_variables = ['src_subject_id', 'vital_sysbp', 'vital_diabp', 'vital_pulse', 'bmi', 'waist', 'height_std', \n",
    "                      'weight_std', 'vtl004a', 'vtl004b', 'vtl004c', 'arith_temperature_ct', 'fatmass', 'fatpct']\n",
    "\n",
    "#Select specific columns\n",
    "df_vitals = df_vitals[selected_variables].copy()\n",
    "\n",
    "df_vitals\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- Lab blood tests -----------------------------------\n",
    "# OUTPUT dataframe: df_lab\n",
    "\n",
    "df_lab = pd.read_excel(dir_input + 'clinlabtests01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_lab = df_lab[df_lab['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"ls_sodium\", \"ls_potassium\", \"ls_chloride\", \"ls_co2\", \"ls_glucose\", \n",
    "         \"ls_creatinine\", \"ls_ureanitrogen\", \"ls_totprotein\", \"ls_albumin\", \"ls_bilirubin\", \"ls_alkaline\", \n",
    "         \"ls_ast\", \"ls_alt\", \"ls_calcium\", \"rsptc_no\", \"rsphdl_no\", \"rspldl_no\", \"rsptrig_no\", \"laba4\", \n",
    "         \"laba9a\", \"ch_ratio\", \"anion\"]\n",
    "\n",
    "#Select specific columns\n",
    "df_lab = df_lab[selected_variables].copy()\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- Medical history -----------------------------------\n",
    "# OUTPUT dataframe: df_medhist\n",
    "\n",
    "df_medhist = pd.read_excel(dir_input + 'coinsmedhistory01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_medhist = df_medhist[df_medhist['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "selected_variables_1 = [\"midihist_001\", \"midihist_002\", \"midihist_004\", \"midihist_006\", \"midihist_007\", \"midihist_008\", \n",
    "         \"midihist_009\", \"midihist_010\", \"midihist_011\", \"midihist_012\", \"midihist_013\", \"midihist_014\", \n",
    "         \"midihist_015\", \"midihist_016\", \"midihist_017\", \"midihist_018\", \"midihist_019\", \"midihist_020\", \n",
    "         \"mhendoce\", \"midihist_025\", \"midihist_026\", \"midihist_036\", \"midihist_040\", \"mhx026a\", \"mhx002a\", \"mhxa1e\", \"psqb02\"]\n",
    "\n",
    "#Remove 9 -> np.nan from the first selection of variables.\n",
    "for variable in selected_variables_1:\n",
    "    df_medhist.loc[df_medhist[variable] == 9, variable] == np.nan\n",
    "\n",
    "#Change Yes - > 1 and No -> 0 for second selection of variables.\n",
    "selected_variable_2 = \"rev_endodiabetes\"\n",
    "df_medhist.loc[df_medhist[selected_variable_2] == 'Yes' ,selected_variable_2] = 1\n",
    "df_medhist.loc[df_medhist[selected_variable_2] == 'No' ,selected_variable_2] = 0\n",
    "\n",
    "selected_variables_3 = [\"mhx028d\", \"bima_28\", \"bima_29\", \"bima_30\", \"bima_31\"]\n",
    "\n",
    "selected_variables = ['src_subject_id'] + selected_variables_1 + [selected_variable_2] + selected_variables_3\n",
    "\n",
    "df_medhist = df_medhist[selected_variables].copy()\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Substance use  -----------------------------------\n",
    "# OUTPUT dataframe: df_subuse\n",
    "\n",
    "df_subuse = pd.read_excel(dir_input + 'subusmf01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_subuse = df_subuse[df_subuse['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "selected_variables = ['src_subject_id', 'subus25', 'subus26', 'subus27', 'ca824', 'subus29', 'subus30', 'scid21', 'subus33', 'subtr4', 'night', 'subtr50', 'outvisit', 'subtr50b', 'subus66', 'surq_1e', 'surq_3a', 'frquency_other', 'subus70']\n",
    "\n",
    "#subus 29 only filled when ca824 is 0. Add them to also have previous use as current + previous use.\n",
    "df_subuse.loc[df_subuse['ca824'] == 1, 'subus29'] = 1\n",
    "\n",
    "\n",
    "df_subuse = df_subuse[selected_variables].copy()\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- Movement side eff.  -------------------------------\n",
    "# OUTPUT dataframe: df_move\n",
    "df_move = pd.read_excel(dir_input + 'aims01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_move = df_move[df_move['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"aims_facial_score_date1\", \"aims_extrem_score_date1\", \"aims_trunk_score_date1\", \"aims_global8_date1\", \"eps1\", \"eps2\", \"eps3\", \"eps4\", \"eps5\", \"epsglob\", \"epsmean\"]\n",
    "\n",
    "df_move = df_move[selected_variables].copy()\n",
    "\n",
    "#Remove 9 - >np.nan\n",
    "remove_list = [\"eps1\", \"eps2\", \"eps3\", \"eps4\", \"eps5\"]\n",
    "for variable in remove_list:\n",
    "    df_move.loc[df_move[variable] == 9, variable] == np.nan\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Side effects scale.  -------------------------------\n",
    "# OUTPUT dataframe: df_sideff\n",
    "df_sideff = pd.read_excel(dir_input + 'prise01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_sideff = df_sideff[df_sideff['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "#Select relevant variables. \n",
    "selected_variables = [\"src_subject_id\", \"gcnst\", \"gdmth\", \"gnsea\", \"nvdzy\", \"eyvsn\", \"urmns\", \"sldif\", \"slmch\", \"sxls\", \"orsls\", \"oftge\", \"saldr\", \"appf\", \"weig\", \"weil\", \"shak\", \"stiff\", \"drodd\", \"osex\", \"pbrea\", \"imsp\", \"sedation\", \"eps\", \"anticholse\", \"incappwt\", \"probwsex\"]\n",
    "df_sideff = df_sideff[selected_variables].copy()\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- Well being scale  ---------------------------------\n",
    "# OUTPUT dataframe: df_wellbeing\n",
    "df_wellbeing = pd.read_excel(dir_input + 'pwb01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_wellbeing = df_wellbeing[df_wellbeing['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "#Select columns.\n",
    "src_subject_id = ['src_subject_id', 'pwb_3', 'pwb_6', 'pwb_8', 'pwb_13', 'pwb_14', 'pwb_21', 'pwb_29', 'pwb_34', 'pwb_36', 'pwb_41', 'pwb_43', 'pwb_47', 'pwb_51', 'pwb_55', 'pwb_64', 'pwb_72', 'pwb_76', 'pwb_80', 'pw_autonomy', 'pw_envmast', 'pw_persgrowth', 'pw_posrel', 'pw_purp', 'pw_selfa', 'wbtotx']\n",
    "df_wellbeing = df_wellbeing[src_subject_id].copy()\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Mental health recovery measure  -------------------\n",
    "# OUTPUT dataframe: df_mhrm\n",
    "df_mhrm = pd.read_excel(dir_input + 'mhrm01.xlsx', skiprows=[1])\n",
    "\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_mhrm = df_mhrm[df_mhrm['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "selected_variables = ['src_subject_id', 'srf019', 'srf020', 'srf021', 'srf022', 'srf023', 'srf024', 'srf025', 'srf026',\n",
    "                      'srf027', 'srf028', 'srf029', 'srf030', 'srf031', 'srf032', 'srf033']\n",
    "\n",
    "# Select variables.\n",
    "df_mhrm = df_mhrm[selected_variables].copy()\n",
    "\n",
    "#remove entries where all selected variables are nan. \n",
    "df_mhrm.dropna(subset=['srf019', 'srf020', 'srf021', 'srf022', 'srf023', 'srf024', 'srf025', 'srf026','srf027', \n",
    "                       'srf028', 'srf029', 'srf030', 'srf031', 'srf032', 'srf033'], how='all', inplace=True)\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Autonomy support scale -------- -------------------\n",
    "# OUTPUT dataframe: df_autsup\n",
    "df_autsup = pd.read_excel(dir_input + 'autsup01.xlsx', skiprows=[1]).filter(regex  = \"^(src_subject_id$|srf|autsupx|visit)\")\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_autsup = df_autsup[df_autsup['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- Medication influences and beliefs ----------------\n",
    "# OUTPUT dataframe: df_bemib\n",
    "df_bemib = pd.read_excel(dir_input + 'bam01.xlsx', skiprows=[1]).filter(regex  = \"^(src_subject_id$|srf|bemibx|visit)\")\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_bemib = df_bemib[df_bemib['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- SRSS Survey (stigma) ------------------------------\n",
    "# OUTPUT dataframe: df_srss\n",
    "\n",
    "df_srss = pd.read_excel(dir_input + 'srss01.xlsx', skiprows=[1]).filter(regex=\"^(src_subject_id$|srf|stigmax|visit$)\")\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_srss = df_srss[df_srss['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Patient self rated globals   -------------------\n",
    "# OUTPUT dataframe: df_selfglob\n",
    "# IMPORTANT: this data was appended at the end of 'mhrm01.xlsx', which is the mental health recovery data. \n",
    "\n",
    "df_selfglob = pd.read_excel(dir_input + 'mhrm01.xlsx', skiprows=[1])\n",
    "\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_selfglob = df_selfglob[df_selfglob['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "selected_variables = ['src_subject_id', 'srf072', 'srf073']\n",
    "\n",
    "# Select variables.\n",
    "df_selfglob = df_selfglob[selected_variables].copy()\n",
    "\n",
    "#remove entries where all selected variables are nan. IMPORTANT: this dataset is a merge of \n",
    "df_selfglob.dropna(subset=['srf072', 'srf073'], how='all', inplace=True)\n",
    "\n",
    "df_selfglob\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Neurocognitive assessment (BACS) ------------------\n",
    "# OUTPUT dataframe: df_neurocog\n",
    "df_neurocog = pd.read_excel(dir_input + 'bac01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_neurocog = df_neurocog[df_neurocog['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "\n",
    "selected_variables = [\"src_subject_id\", \"bacs_dstotalscore\", \"bacs_sc_total\", \"bacs_tl_total\", \"bacs_vmttot\", \"bacs_fltot\", \"bacvm1\", \"bacvm2\", \"bacvm3\",\n",
    "           \"bacvm4\", \"bacvm5\", \"bactmts\", \"bacflua\", \"bacfluf\", \"bacflus\"]\n",
    "\n",
    "df_neurocog = df_neurocog[selected_variables].copy()\n",
    "\n",
    "#Rows are repeated, so we group by. The max does not matter since the numbers are repeated. \n",
    "df_neurocog = df_neurocog.groupby('src_subject_id').agg('max').reset_index()\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Family assessment scale --------------------------\n",
    "# OUTPUT dataframe: df_famburd\n",
    "\n",
    "df_famburd = pd.read_excel(dir_input + 'famburd01.xlsx', skiprows=[1]).filter(regex=\"^(src_subject_id$|fas|f1d|f2p|f3g|f4t|f5w|fbur|visit$)\")\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_famburd = df_famburd[df_famburd['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "# Replace values of 9 with np.nan in columns starting with 'fas'\n",
    "fas_columns = [col for col in df_famburd.columns if col.startswith('fas')]\n",
    "df_famburd[fas_columns] = df_famburd[fas_columns].replace(9, np.nan)\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#------------- Recovery outcomes assessment ------------------------\n",
    "# OUTPUT dataframe: df_famrecov\n",
    "\n",
    "df_famrecov = pd.read_excel(dir_input + 'famrecov01.xlsx', skiprows=[1]).filter(regex=\"^(src_subject_id$|roa004|roa005|roa006|roa007|roa008|roa010|roa011|roa012|roa013|spous|roa015|roa016|visit$)\")\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_famrecov = df_famrecov[df_famrecov['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "# replace 99 and 9 with nan.\n",
    "roa_columns = [col for col in df_famburd.columns if (col.startswith('roa') or col.startswith('spous'))]\n",
    "df_famrecov[roa_columns] = df_famrecov[roa_columns].replace(9, np.nan)\n",
    "df_famrecov[roa_columns] = df_famrecov[roa_columns].replace(99, np.nan)\n",
    "\n",
    "#Dummy coding.\n",
    "dummy_coded = pd.get_dummies(df_famrecov['roa004'], prefix = 'roa004')\n",
    "df_famrecov.drop(columns = 'roa004', inplace = True)\n",
    "df_famrecov = pd.concat([df_famrecov, dummy_coded], axis = 1)\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- Demographics, diagnoses, and other participant descriptors ------------------------\n",
    "# OUTPUT dataframe: df_demo, df_covars\n",
    "\n",
    "#Read the covars: site. \n",
    "df_covars = pd.read_excel(dir_input + 'ptchart01.xlsx', skiprows=[1], nrows=404).filter(regex=\"^(src_subject_id$|site$|visit)\")\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_covars = df_covars[df_covars['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "# Read the childcare variables. IMPORTANT: this are variables merged at the end of the raw file which are empty in the rows where df_demo is not empty. \n",
    "df_childcare = pd.read_excel(dir_input + 'ptchart01.xlsx', skiprows=[1]).filter(regex=\"^(src_subject_id$|chldyn$|numchild$|children_household$|chldresp$|chldlvyn$|visit)\")\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_childcare = df_childcare[df_childcare['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "# Remove rows where all selected variables are NaN\n",
    "df_childcare = df_childcare.dropna(subset=['chldyn', 'numchild', 'children_household', 'chldresp', 'chldlvyn'], how='all')\n",
    "df_childcare = df_childcare[['src_subject_id', 'chldyn', 'numchild', 'children_household', 'chldresp', 'chldlvyn']].copy()\n",
    "\n",
    "#Dummy code chldlvyn\n",
    "dummy_coded = pd.get_dummies(df_childcare['chldlvyn'], prefix = 'chldlvyn')\n",
    "df_childcare.drop(columns = 'chldlvyn', inplace = True)\n",
    "df_childcare = pd.concat([df_childcare, dummy_coded], axis = 1)\n",
    "\n",
    "\n",
    "df_demo = pd.read_excel(dir_input + 'ptchart01.xlsx', skiprows=[1], nrows=404)\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_demo = df_demo[df_demo['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "#Variables that need converting into binary. \n",
    "selected_variable_00 = 'sex'\n",
    "selected_variable_01 = 'treatgrp'\n",
    "selected_variable_02 = 'refothers'\n",
    "selected_variable_03 = 'ethnicity'\n",
    "\n",
    "#Converting sex into binary.\n",
    "df_demo.loc[df_demo[selected_variable_00] == 'F', selected_variable_00] = 2\n",
    "df_demo.loc[df_demo[selected_variable_00] == 'M', selected_variable_00] = 1\n",
    "\n",
    "#Converting treatment into binary.\n",
    "df_demo.loc[df_demo[selected_variable_01] == 'N', selected_variable_01] = 2\n",
    "df_demo.loc[df_demo[selected_variable_01] == 'CC', selected_variable_01] = 1\n",
    "\n",
    "#Converting referal source into binary.\n",
    "df_demo.loc[df_demo[selected_variable_02] == 'In treatment at the site or usual referral source', selected_variable_02] = 2\n",
    "df_demo.loc[df_demo[selected_variable_02] == 'Community outreach', selected_variable_02] = 1\n",
    "\n",
    "#Converting ethnicity source into binary.\n",
    "df_demo.loc[df_demo[selected_variable_03] == 'Not Hispanic or Latino', selected_variable_03] = 2\n",
    "df_demo.loc[df_demo[selected_variable_03] == 'Hispanic or Latino', selected_variable_03] = 1\n",
    "\n",
    "#Variables that do not need modification.\n",
    "selected_variables_1 = ['src_subject_id', 'sex', 'treatgrp', 'refothers', 'ethnicity', 'dup', 'interview_age', 'studntyn', 'workyn', 'job1yn', 'job1age', \n",
    "             'longest', 'lnghrs', 'job_pthi', 'job_ptcu', 'dem_09a', 'dem_09b', 'ageill', 'hpl_02', 'psyhspyn', 'age_1st_hosp', 'numhosp1', 'tdayshosp', 'wkslsthp',\n",
    "             'wksset', 'lfapcon', 'lfapbl', 'curapbl', 'sgafgayn', 'psych_subonset']\n",
    "\n",
    "#Variables that need np.nan -> 0 and dummy coding. \n",
    "selected_variables_2 = ['alcoh30', 'sedat30', 'cannab30', 'stimu30', 'opioid30', 'coca30', 'pcp30', 'poly30', 'other30']\n",
    "\n",
    "for var in selected_variables_2:\n",
    "    df_demo.loc[df_demo[var] == np.nan, var] = 0\n",
    "\n",
    "\n",
    "#Variables that need dummy coding.\n",
    "selected_variables_3 = ['race', 'das1ms', 'curres', 'educpt', 'educmo', \n",
    "                        'educfa', 'trt_set', 'dxbase', 'alcohlf', 'sedatlf', 'cannablf', 'stimulf', 'opioidlf', \n",
    "                        'cocalf', 'pcplf', 'polylf', 'otherlf']\n",
    "\n",
    "#Get all relevant variables\n",
    "selected_variables = selected_variables_1 + selected_variables_2 + selected_variables_3\n",
    "df_demo = df_demo[selected_variables].copy()\n",
    "\n",
    "#Remove 99 -> np.nan\n",
    "for var in selected_variables:\n",
    "    df_demo.loc[df_demo[var] == 99, var] = np.nan\n",
    "\n",
    "#Dummy code the variables.\n",
    "for var in selected_variables_2 + selected_variables_3:\n",
    "    #Dummy code the variable and replace with dummy coding.\n",
    "    dummy_coded = pd.get_dummies(df_demo[var], prefix = var)\n",
    "    df_demo.drop(columns = var, inplace = True)\n",
    "    df_demo = pd.concat([df_demo, dummy_coded], axis = 1)\n",
    "\n",
    "#Merge df_demo and df_childcare on src_subject_id\n",
    "df_demo = df_demo.merge(df_childcare, on='src_subject_id', how = 'left')\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "\n",
    "#------------- Smoking instrument ---------------------------------\n",
    "# OUTPUT dataframe: df_fager\n",
    "\n",
    "df_fager = pd.read_excel(dir_input + 'fagerstrom01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_fager = df_fager[df_fager['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "selected_variables = ['src_subject_id', 'ftnd_7', 'q01_first_cig', 'q02_forbidden', 'q03_give_up', 'q04_per_day', \n",
    "                      'q05_frequency', 'q06_ill', 'ftnd_score_total', 'mhx052', 'mhx053', 'mhx054', \n",
    "                      'mhx055', 'mhx056', 'mhx057', 'mhx058', 'chwscore']\n",
    "\n",
    "#Select the variables.\n",
    "df_fager = df_fager[selected_variables].copy()\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "#------------- Service utilisation (monhly) ------------------------\n",
    "# OUTPUT dataframe: df_servm\n",
    "# IMPORTANT: variables included in this dataset have very specific questions. \n",
    "#It is not clear how these might be helpful in ML analyses.\n",
    "df_servm = pd.read_excel(dir_input + 'surf01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_servm = df_servm[df_servm['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "selected_variables = ['src_subject_id', 'inpat1a', 'inpat1b', 'inpat1c', 'inpat1d', 'surfm31', 'night2', 'surfm41', 'night3', \n",
    "         'srfa5a1', 'srfa5a2', 'srfa5a3', 'srfa5c1', 'srfa5c2', 'srfa5c3', 'srfa5d1', 'srfa5d2', \n",
    "         'srfa5d3', 'srfa5e1', 'srfa5e2', 'srfa5e3', 'srfa5f1', 'srfa5f2', 'srfa5f3', 'srfa5g1', \n",
    "         'srfa5g2', 'srfa5g3', 'srfa5h1', 'srfa5j1', 'srfa5j2', 'srfa5j3', 'srfa5k1', 'srfa5k2', \n",
    "         'srfa5k3', 'srfa5l1', 'srfa5l2', 'srfa5l3', 'srfa5o1', 'srfa5o2', 'srfa5o3', 'srfa6a', \n",
    "         'srfa6b', 'srfa6c', 'srfa6d', 'srfa6e', 'srfa6f', 'srfa6g', 'srfa6h', 'srf1', 'srf2', \n",
    "         'srf3', 'srf4', 'surm007', 'surm007b', 'surm008', 'surm008b', 'surm011', \n",
    "         'surm013', 'dworked', 'hworked', 'earnweek', 'surfq2', 'surfq3', 'surfq3a', 'surfq3b', \n",
    "         'surm019', 'surm041', 'surm041a', 'surm041b', 'surm042', 'surm042a', 'surm042b', 'surm044c', \n",
    "         'surm045', 'outpprof', 'surm045b', 'surm046', 'surm046a', 'surm046b', 'surm048c', 'surm049', \n",
    "         'surm049a', 'surm049b', 'surm052', 'surm052a', 'surm059', 'surm060', 'surm061', 'surm062', \n",
    "         'surm063', 'surm064', 'surm065', 'surm071', 'surm071a', 'surm072', 'surm072a', 'surm073', \n",
    "         'surm073a', 'surm074', 'surm074a', 'wrkfrpay', 'surm009', 'surm012', 'surfq2a', 'surm043']\n",
    "#Get only selected variables.\n",
    "df_servm = df_servm[selected_variables].copy()\n",
    "\n",
    "#Dummy code the categorical variables.\n",
    "for var in ['surm009', 'surm012', 'surm043']:\n",
    "    #Dummy code the variable and replace with dummy coding.\n",
    "    dummy_coded = pd.get_dummies(df_servm[var], prefix = var)\n",
    "    df_servm.drop(columns = var, inplace = True)\n",
    "    df_servm = pd.concat([df_servm, dummy_coded], axis = 1)\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------- Service utilisation (quarter) ------------------------\n",
    "# OUTPUT dataframe: df_servq\n",
    "# IMPORTANT: variables included in this dataset have very specific questions. \n",
    "#It is not clear how these might be helpful in ML analyses.\n",
    "\n",
    "df_servq = pd.read_excel(dir_input + 'surfq01.xlsx', skiprows=[1])\n",
    "\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_servq = df_servq[df_servq['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "# Variables to extract.\n",
    "selected_variables = ['src_subject_id', 'surfqa', 'surfqaa', 'surfqb', 'surfqba', 'surfqc', 'surfqca', 'surfqd', 'surfqda', 'surfqe', 'surfqea', \n",
    "         'surfqh', 'surfqha', 'surfqi', 'surfqia', 'surfqk', 'surfqka', 'surfql', 'surfqla', 'surfqm', 'priv1a', \n",
    "         'publica', 'medcaid', 'insur2g', 'surq018', 'surq019', 'surq020', 'surq021', 'surq026', 'surq027', \n",
    "         'instype', 'arrest', 'police', 'court', 'nitejail', 'parole', 'officer', 'timeoff', 'surq011']\n",
    "\n",
    "df_servq = df_servq[selected_variables].copy()\n",
    "\n",
    "# Variables to convert 3 -> np.nan\n",
    "selected_variables_2 =  ['surfqa', 'surfqb', 'surfqc', 'surfqd', 'surfqe', 'surfqh', 'surfqi', 'surfqk', 'surfql', \n",
    "                       'surfqm', 'priv1a', 'publica', 'medcaid']\n",
    "\n",
    "#Convert 3 to nan in selected variables.\n",
    "for var in selected_variables_2:\n",
    "    df_servq.loc[df_servq[var] == 3,var] = np.nan\n",
    "\n",
    "#Dummy code the variable and replace with dummy coding.\n",
    "dummy_coded = pd.get_dummies(df_servq['insur2g'], prefix = var)\n",
    "df_servq.drop(columns = 'insur2g', inplace = True)\n",
    "df_servq = pd.concat([df_servq, dummy_coded], axis = 1)\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#-------------- Medication at consent ----------------------------\n",
    "# OUTPUT dataframe: df_medcon\n",
    "df_medcon_v1 = pd.read_excel(dir_input + 'medcon01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_medcon_v1 = df_medcon_v1[df_medcon_v1['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "selected_variables = ['src_subject_id', 'adhetpc1']\n",
    "\n",
    "df_medcon_v1 = df_medcon_v1[selected_variables].copy()\n",
    "\n",
    "# Dummy code the drug.\n",
    "dummy_coded = pd.get_dummies(df_medcon_v1['adhetpc1'], prefix = 'adhetpc1')\n",
    "df_medcon_v1.drop(columns = 'adhetpc1', inplace = True)\n",
    "df_medcon_v1 = pd.concat([df_medcon_v1, dummy_coded], axis = 1)\n",
    "\n",
    "#Agreggate all columns. \n",
    "df_medcon = df_medcon_v1.groupby('src_subject_id').agg('max').reset_index()\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#-------------- Medication adherence -----------------------------\n",
    "# OUTPUT dataframe: df_medadh\n",
    "\n",
    "df_medadh = pd.read_excel(dir_input + 'adh01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_medadh = df_medadh[df_medadh['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "selected_variables = ['src_subject_id', \"nbrmeds\", \"nbrpill1\", \"daysnot1\", \"daysles1\", \"nbrpill2\", \"daysnot2\", \"daysles2\", \"nbrpilex\", \"nbrpilms\"]\n",
    "df_medadh = df_medadh[selected_variables].copy()\n",
    "\n",
    "#Create a variable of ratio of pills missed. \n",
    "df_medadh['nbrpilratio'] = df_medadh['nbrpilms']/df_medadh['nbrpilex']\n",
    "#-----------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6be5ca61-d0e3-4e4c-984c-f12e352245fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#Storing Data and Merging\n",
    "################################################################################\n",
    "# Sergio Mena Ortega, 2024\n",
    "\n",
    "#Writing individual datasets into excel.\n",
    "df_panss.to_excel(dir_output + 'Individual Datasets/panss.xlsx', index=None) #\n",
    "df_cgi.to_excel(dir_output + 'Individual Datasets/cgi.xlsx', index=None) #\n",
    "df_cdss.to_excel(dir_output + 'Individual Datasets/cdss.xlsx', index=None) #\n",
    "df_qol.to_excel(dir_output + 'Individual Datasets/qol.xlsx', index=None) #\n",
    "df_compliance.to_excel(dir_output + 'Individual Datasets/comp.xlsx', index=None) #\n",
    "df_sf12.to_excel(dir_output + 'Individual Datasets/sf12.xlsx', index=None) #\n",
    "df_vitals.to_excel(dir_output + 'Individual Datasets/vitals.xlsx', index=None) #\n",
    "df_lab.to_excel(dir_output + 'Individual Datasets/lab.xlsx', index=None) #\n",
    "df_medhist.to_excel(dir_output + 'Individual Datasets/medhist.xlsx', index=None) #\n",
    "df_subuse.to_excel(dir_output + 'Individual Datasets/subuse.xlsx', index=None) #\n",
    "df_move.to_excel(dir_output + 'Individual Datasets/move.xlsx', index=None) # \n",
    "df_sideff.to_excel(dir_output + 'Individual Datasets/sideff.xlsx', index=None) #\n",
    "df_wellbeing.to_excel(dir_output + 'Individual Datasets/wellbeing.xlsx', index=None) #\n",
    "df_mhrm.to_excel(dir_output + 'Individual Datasets/mhrm.xlsx', index=None) #\n",
    "df_autsup.to_excel(dir_output + 'Individual Datasets/autsup.xlsx', index=None) #\n",
    "df_bemib.to_excel(dir_output + 'Individual Datasets/bemib.xlsx', index=None) # \n",
    "df_srss.to_excel(dir_output + 'Individual Datasets/srss.xlsx', index=None) #\n",
    "df_selfglob.to_excel(dir_output + 'Individual Datasets/selfglob.xlsx', index=None) #\n",
    "df_neurocog.to_excel(dir_output + 'Individual Datasets/neurocog.xlsx', index=None) #\n",
    "df_famburd.to_excel(dir_output + 'Individual Datasets/famburd.xlsx', index=None) #\n",
    "df_famrecov.to_excel(dir_output + 'Individual Datasets/famrecov.xlsx', index=None) #\n",
    "df_demo.to_excel(dir_output + 'Individual Datasets/demo.xlsx', index=None) #\n",
    "df_covars.to_excel(dir_output + 'Individual Datasets/covars.xlsx', index=None) #\n",
    "df_fager.to_excel(dir_output + 'Individual Datasets/fager.xlsx', index=None) #\n",
    "df_servm.to_excel(dir_output + 'Individual Datasets/servm.xlsx', index=None) #\n",
    "df_servq.to_excel(dir_output + 'Individual Datasets/servq.xlsx', index=None) #\n",
    "df_medcon.to_excel(dir_output + 'Individual Datasets/medcon.xlsx', index=None) #\n",
    "df_medadh.to_excel(dir_output + 'Individual Datasets/medadh.xlsx', index=None) #\n",
    "\n",
    "#Merging data into 4 categories: clinical+sociodemographic, cognitive, QoL and lab data.\n",
    "\n",
    "#Get the original ids. \n",
    "df_id =  pd.read_excel(dir_input + 'ptchart01.xlsx', skiprows=[1], nrows=404).filter(regex=\"^(src_subject_id$|visit$)\")\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_id = df_id[df_id['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "\n",
    "\n",
    "#Clinical and sociodemographic data category.\n",
    "df_clin_and_socio = df_id.copy()\n",
    "list_of_dataframes = [df_demo, df_panss, df_cdss, df_cgi, df_famburd, df_famrecov, \n",
    "                      df_compliance, df_servm, df_servq, df_fager, df_medcon, df_medadh,\n",
    "                      df_selfglob, df_srss, df_bemib, df_autsup, df_mhrm, df_sideff, df_move, df_subuse, df_medhist]\n",
    "\n",
    "for data in list_of_dataframes:\n",
    "    df_clin_and_socio = pd.merge(df_clin_and_socio, data, on='src_subject_id', how='left')\n",
    "    \n",
    "#Save to excel.    \n",
    "df_clin_and_socio.to_excel(dir_output+'Merged Datasets/clinical_and_sociodemographic.xlsx', index = False)\n",
    "\n",
    "\n",
    "#Health category. \n",
    "df_health = pd.merge(df_id, df_lab, on='src_subject_id', how='left')\n",
    "df_health = pd.merge(df_health, df_sf12, on='src_subject_id', how='left')\n",
    "df_health = pd.merge(df_health, df_vitals, on='src_subject_id', how='left')\n",
    "#Save to excel.    \n",
    "df_health.to_excel(dir_output+'Merged Datasets/health.xlsx', index = False)\n",
    "\n",
    "\n",
    "#Cognitive category. \n",
    "df_cognitive = pd.merge(df_id, df_neurocog, on='src_subject_id', how='left')\n",
    "#Save to excel.    \n",
    "df_cognitive.to_excel(dir_output+'Merged Datasets/cognitive.xlsx', index = False)\n",
    "\n",
    "##Quality of life category . \n",
    "df_quality_of_life = pd.merge(df_id, df_qol, on='src_subject_id', how='left')\n",
    "df_quality_of_life = pd.merge(df_quality_of_life, df_wellbeing, on='src_subject_id', how='left')\n",
    "#Save to excel.    \n",
    "df_quality_of_life.to_excel(dir_output+'Merged Datasets/quality_of_life.xlsx', index = False)\n",
    "\n",
    "##Covariates (df_covariates).\n",
    "df_covariates = pd.merge(df_id, df_covars, on='src_subject_id', how='left')\n",
    "#Save to excel.    \n",
    "df_covariates.to_excel(dir_output+'Merged Datasets/covariates.xlsx', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4ab2ac2-a377-4f9f-a38a-0afb09c653c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_subject_id</th>\n",
       "      <th>adhetpc1_1.0</th>\n",
       "      <th>adhetpc1_2.0</th>\n",
       "      <th>adhetpc1_3.0</th>\n",
       "      <th>adhetpc1_4.0</th>\n",
       "      <th>adhetpc1_5.0</th>\n",
       "      <th>adhetpc1_6.0</th>\n",
       "      <th>adhetpc1_7.0</th>\n",
       "      <th>adhetpc1_8.0</th>\n",
       "      <th>adhetpc1_9.0</th>\n",
       "      <th>adhetpc1_11.0</th>\n",
       "      <th>adhetpc1_12.0</th>\n",
       "      <th>adhetpc1_13.0</th>\n",
       "      <th>adhetpc1_14.0</th>\n",
       "      <th>adhetpc1_16.0</th>\n",
       "      <th>adhetpc1_17.0</th>\n",
       "      <th>adhetpc1_19.0</th>\n",
       "      <th>adhetpc1_21.0</th>\n",
       "      <th>adhetpc1_22.0</th>\n",
       "      <th>adhetpc1_23.0</th>\n",
       "      <th>adhetpc1_24.0</th>\n",
       "      <th>adhetpc1_25.0</th>\n",
       "      <th>adhetpc1_30.0</th>\n",
       "      <th>adhetpc1_31.0</th>\n",
       "      <th>adhetpc1_32.0</th>\n",
       "      <th>adhetpc1_34.0</th>\n",
       "      <th>adhetpc1_35.0</th>\n",
       "      <th>adhetpc1_36.0</th>\n",
       "      <th>adhetpc1_37.0</th>\n",
       "      <th>adhetpc1_38.0</th>\n",
       "      <th>adhetpc1_39.0</th>\n",
       "      <th>adhetpc1_41.0</th>\n",
       "      <th>adhetpc1_42.0</th>\n",
       "      <th>adhetpc1_43.0</th>\n",
       "      <th>adhetpc1_44.0</th>\n",
       "      <th>adhetpc1_50.0</th>\n",
       "      <th>adhetpc1_70.0</th>\n",
       "      <th>adhetpc1_80.0</th>\n",
       "      <th>adhetpc1_90.0</th>\n",
       "      <th>adhetpc1_100.0</th>\n",
       "      <th>adhetpc1_101.0</th>\n",
       "      <th>adhetpc1_110.0</th>\n",
       "      <th>adhetpc1_120.0</th>\n",
       "      <th>adhetpc1_140.0</th>\n",
       "      <th>adhetpc1_160.0</th>\n",
       "      <th>adhetpc1_170.0</th>\n",
       "      <th>adhetpc1_180.0</th>\n",
       "      <th>adhetpc1_190.0</th>\n",
       "      <th>adhetpc1_200.0</th>\n",
       "      <th>adhetpc1_205.0</th>\n",
       "      <th>adhetpc1_210.0</th>\n",
       "      <th>adhetpc1_220.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14123</th>\n",
       "      <td>560</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14124</th>\n",
       "      <td>560</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1785 rows  52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       src_subject_id  adhetpc1_1.0  adhetpc1_2.0  adhetpc1_3.0  adhetpc1_4.0  \\\n",
       "0                  47         False         False         False         False   \n",
       "1                  47         False         False         False         False   \n",
       "...               ...           ...           ...           ...           ...   \n",
       "14123             560         False         False         False         False   \n",
       "14124             560         False         False         False         False   \n",
       "\n",
       "       adhetpc1_5.0  adhetpc1_6.0  adhetpc1_7.0  adhetpc1_8.0  adhetpc1_9.0  \\\n",
       "0             False         False         False         False         False   \n",
       "1             False         False         False         False         False   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "14123         False         False         False         False         False   \n",
       "14124         False         False         False         False         False   \n",
       "\n",
       "       adhetpc1_11.0  adhetpc1_12.0  adhetpc1_13.0  adhetpc1_14.0  \\\n",
       "0              False          False          False          False   \n",
       "1              False          False          False          False   \n",
       "...              ...            ...            ...            ...   \n",
       "14123          False          False           True          False   \n",
       "14124          False          False          False          False   \n",
       "\n",
       "       adhetpc1_16.0  adhetpc1_17.0  adhetpc1_19.0  adhetpc1_21.0  \\\n",
       "0              False          False          False          False   \n",
       "1              False          False          False          False   \n",
       "...              ...            ...            ...            ...   \n",
       "14123          False          False          False          False   \n",
       "14124          False          False          False          False   \n",
       "\n",
       "       adhetpc1_22.0  adhetpc1_23.0  adhetpc1_24.0  adhetpc1_25.0  \\\n",
       "0              False          False          False          False   \n",
       "1              False          False          False          False   \n",
       "...              ...            ...            ...            ...   \n",
       "14123          False          False          False          False   \n",
       "14124          False          False          False          False   \n",
       "\n",
       "       adhetpc1_30.0  adhetpc1_31.0  adhetpc1_32.0  adhetpc1_34.0  \\\n",
       "0              False          False          False          False   \n",
       "1              False          False          False          False   \n",
       "...              ...            ...            ...            ...   \n",
       "14123          False          False          False          False   \n",
       "14124          False          False          False          False   \n",
       "\n",
       "       adhetpc1_35.0  adhetpc1_36.0  adhetpc1_37.0  adhetpc1_38.0  \\\n",
       "0              False          False          False          False   \n",
       "1              False          False          False          False   \n",
       "...              ...            ...            ...            ...   \n",
       "14123          False          False          False          False   \n",
       "14124          False          False          False          False   \n",
       "\n",
       "       adhetpc1_39.0  adhetpc1_41.0  adhetpc1_42.0  adhetpc1_43.0  \\\n",
       "0              False          False          False          False   \n",
       "1              False          False          False          False   \n",
       "...              ...            ...            ...            ...   \n",
       "14123          False          False          False          False   \n",
       "14124          False          False          False          False   \n",
       "\n",
       "       adhetpc1_44.0  adhetpc1_50.0  adhetpc1_70.0  adhetpc1_80.0  \\\n",
       "0              False           True          False          False   \n",
       "1              False          False           True          False   \n",
       "...              ...            ...            ...            ...   \n",
       "14123          False          False          False          False   \n",
       "14124          False          False          False          False   \n",
       "\n",
       "       adhetpc1_90.0  adhetpc1_100.0  adhetpc1_101.0  adhetpc1_110.0  \\\n",
       "0              False           False           False           False   \n",
       "1              False           False           False           False   \n",
       "...              ...             ...             ...             ...   \n",
       "14123          False           False           False           False   \n",
       "14124          False            True           False           False   \n",
       "\n",
       "       adhetpc1_120.0  adhetpc1_140.0  adhetpc1_160.0  adhetpc1_170.0  \\\n",
       "0               False           False           False           False   \n",
       "1               False           False           False           False   \n",
       "...               ...             ...             ...             ...   \n",
       "14123           False           False           False           False   \n",
       "14124           False           False           False           False   \n",
       "\n",
       "       adhetpc1_180.0  adhetpc1_190.0  adhetpc1_200.0  adhetpc1_205.0  \\\n",
       "0               False           False           False           False   \n",
       "1               False           False           False           False   \n",
       "...               ...             ...             ...             ...   \n",
       "14123           False           False           False           False   \n",
       "14124           False           False           False           False   \n",
       "\n",
       "       adhetpc1_210.0  adhetpc1_220.0  \n",
       "0               False           False  \n",
       "1               False           False  \n",
       "...               ...             ...  \n",
       "14123           False           False  \n",
       "14124           False           False  \n",
       "\n",
       "[1785 rows x 52 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------- Medication at consent ----------------------------\n",
    "# OUTPUT dataframe: df_medcon\n",
    "df_medcon_v1 = pd.read_excel(dir_input + 'medcon01.xlsx', skiprows=[1])\n",
    "\n",
    "# Filter the visit, just baseline, and drop the visit column.  \n",
    "df_medcon_v1 = df_medcon_v1[df_medcon_v1['visit'] == 'B'].drop(columns = 'visit')\n",
    "\n",
    "selected_variables = ['src_subject_id', 'adhetpc1']\n",
    "\n",
    "df_medcon_v1 = df_medcon_v1[selected_variables].copy()\n",
    "\n",
    "# Dummy code the drug.\n",
    "dummy_coded = pd.get_dummies(df_medcon_v1['adhetpc1'], prefix = 'adhetpc1')\n",
    "df_medcon_v1.drop(columns = 'adhetpc1', inplace = True)\n",
    "df_medcon_v1 = pd.concat([df_medcon_v1, dummy_coded], axis = 1)\n",
    "\n",
    "#Agreggate all columns. \n",
    "df_medcon = df_medcon_v1.groupby('src_subject_id').agg('max').reset_index()\n",
    "\n",
    "#-----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b7a49-7264-4885-81b3-7ca513b90528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medcon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
